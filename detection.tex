\documentclass[letterpaper,preprint]{aastex}
\usepackage{bm}
\usepackage{calc}
\usepackage{amssymb, amsmath}
\usepackage{hyperref}
\newcounter{address}
\newcommand{\doctype}{paper}
\newcommand{\equationname}{equation}
\newcommand{\eqnref}[1]{\mbox{\equationname~\ref{#1}}}
\newcommand{\appref}[1]{\mbox{Appendix~\ref{#1}}}
\newcommand{\Appref}[1]{\mbox{Appendix~\ref{#1}}}
\newcommand{\tabref}[1]{\mbox{Table~\ref{#1}}}

\newcommand{\niceurl}[1]{\mbox{\href{#1}{\textsl{#1}}}}

\newcommand{\latin}[1]{\emph{#1}}
\newcommand{\etal}{\latin{et\,al.}}
\newcommand{\ie}{\latin{i.e.}}
\newcommand{\apriori}{\latin{a priori}}
\newcommand{\sn}{{[s/n]}}
\newcommand{\sntotal}{\sn_{\mathrm{total}}}
\newcommand{\fwhm}{{\theta_{\mathrm{FWHM}}}}
\newcommand{\RA}{{\mathrm{RA}}}
\newcommand{\Dec}{{\mathrm{Dec}}}
\newcommand{\vecmu}{\bm{\vec{\mu}}}
\newcommand{\mualpha}{{\mu_\alpha}}
\newcommand{\mudelta}{{\mu_\delta}}
\newcommand{\var}[1]{\mathrm{Var}({#1})}
\newcommand{\unit}[1]{\mathrm{#1}}
\renewcommand{\mag}{\unit{mag}}
\newcommand{\s}{\unit{s}}
\newcommand{\yr}{\unit{yr}}
\newcommand{\km}{\unit{km}}
\newcommand{\pc}{\unit{pc}}
\newcommand{\kpc}{\unit{kpc}}
\newcommand{\mas}{\unit{mas}}
\newcommand{\pix}{\unit{pix}}
\newcommand{\kmpers}{\km\,\s^{-1}}
\newcommand{\masperyr}{\mas\,\yr^{-1}}
\renewcommand{\arcsec}{\unit{arcsec}}
\newcommand{\arcsecperyr}{\arcsec\,\yr^{-1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\mean}[1]{\left<{#1}\right>}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\figpart}[1]{\textbf{#1}}
\newcommand{\fig}{Figure}
\newcommand{\figref}[1]{\mbox{\fig~\ref{#1}}}
\newcommand{\detmap}{detection map}
\newcommand{\Detmap}{Detection map}
\newcommand{\fluxmap}{flux map}
\newcommand{\fmap}{F}
\newcommand{\drawnfrom}{\sim}
\newcommand{\gaussianN}{\mathcal{N}}
\newcommand{\gaussian}[1]{\gaussianN\!\left(#1\right)}
\newcommand{\gaussx}[1]{\hat{\gaussianN}\!\left(#1\right)}
%\newcommand{\gaussx}[1]{\mathfrak{N}\!\left(#1\right)}
%\newcommand{\psf}{\mathrm{psf}}
\newcommand{\psf}{\psi}
\newcommand{\psfat}[1]{\psf_{#1}}
\newcommand{\psfnorm}{\norm{\bm{\psf}}}

\newcommand{\signoise}{[S/N]}
\newcommand{\snr}[1]{\mathbb{SN}(#1)}
%\newcommand{\snr}[1]{\mathcal{SN}(#1)}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\expect}[1]{\left\langle #1 \right\rangle}
\renewcommand{\var}[1]{\mathrm{var}\left( #1 \right)}
\newcommand{\sky}{\mathrm{sky}}
\newcommand{\psfw}{w}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\noise}{e}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\thetavec}{\vec{\theta}}
\newcommand{\avec}{\vec{a}}
\newcommand{\ivec}{\vec{i}}
\newcommand{\jvec}{\vec{j}}
\newcommand{\kvec}{\vec{k}}
\newcommand{\cvec}{\vec{c}}
\newcommand{\posvec}{\vec{x}}
\newcommand{\coord}[2]{(#1, #2)}
\newcommand{\iina}{\ivec \,\, \mathrm{in} \,\, \mathcal{A}}

\begin{document}
\title{Principled point-source detection in collections of astronomical images}
\author{%
  Dustin Lang\altaffilmark{1,2,3},
  David W. Hogg\altaffilmark{4,5},
  \& Others}
\altaffiltext{1}{To whom correspondence should be addressed; \texttt{dstn@cmu.edu}}
\altaffiltext{2}{McWilliams Center for Cosmology, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA}
%\altaffiltext{3}{Princeton University Observatory, Princeton, NJ 08544, USA}
\altaffiltext{4}{Center for Cosmology and Particle Physics, Department of Physics, New York University, 4 Washington Place, New York, NY 10003, USA}
\altaffiltext{5}{Max-Planck-Institut f\"ur Astronomie, K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\begin{abstract}
\end{abstract}

\keywords{
    methods:~statistical ---
    techniques:~image~processing
}

\section{Introduction}

There are few operations in astronomy more important than the
detection of stars or point sources.
Indeed, many astronomical discoveries come down to point-source
detection.
What is the best method for performing such detection?
Here we answer that question, in the limited context of isolated
sources, uniform sky-limited noise, and well-understood point-spread
function.
Even in this limited context, the subject is rich and valuable; more
general---and more difficult---cases will be illuminated if we can
understand the simplest case first.

Fundamentally, when much is understood about a signal latent in noisy
data, the best detection methods are (or look like) \emph{matched
filters}.
A matched filter is a model of the expected signal with which the data
are \emph{cross-correlated}.% (often wrongly called ``convolved'').
Peaks in the cross-correlation are candidate signal detections.
In astronomical point-source detection, the expected signal is the
point-spread function (PSF), and the cross-correlation operation is often
wrongly called ``convolution''.
Matched filters are well used in astronomy, in contexts ranging from
spectroscopy (CITE) to ultra-faint galaxies (CITE) to gravitational
radiation (CITE).
[ADD ADDITIONAL REFS]

In what follows, we will argue for matched filtering for point-source
detection.  This is not new (CITE); what is new is that we consider
the common context of heterogeneous (in point-spread function and
sensitivity) multi-epoch, multi-band imaging.
%
While the optimality of matched filtering for single-image point
source detection is well known by astronomers, the straightforward
mathematics behind it is often not, leading to a misconception that
this is simply an algorithmic choice.  To our knowledge, the optimal%
\footnote{In this \doctype\ we use ``optimal'' in a technical sense,
  of saturating the Cramer--Rao bound under stated assumptions.  We
  encourage other authors to do the same!}
method of combining multiple images with different properties to
obtain the greatest possible sensitivity to point sources has not been
written down in the astronomical literature.  The mathematics are
straightforward and the resulting procedure is simple to implement and
computationally efficient.

Perhaps more controversially, we go on to argue that when imaging in
multiple bands is available, one should use a filter matched to the
spectral-energy distribution (SED) of the sources to be detected.
This SED-matched filtering, as we will call it, makes explicit the
assumptions that are implicitly embedded in any method that attempts
to detect sources by combining imaging from multiple bands.

In the Real World, astronomers never precisely know their point-spread
function, their noise model, their flat-field (or other calibration
parameters), nor the spectral-energy distributions of the sources of
greatest interest.
Also, often, the sources of interest aren't point sources or perhaps
vary with time.
In these cases, we advocate parameterizing ignorance, and operating
with the union of all possibly appropriate matched filters.
We will fully execute this idea here when it comes to spectral-energy
distributions, but there are natural extensions to deal with
point-spread function, noise-model, calibration, and time-domain
uncertainties.
DSTN: WE SHOULD RETURN TO THESE ISSUES IN THE DISCUSSION.


A ``traditional'' approach for detecting sources in multi-epoch
imaging is to co-add the images and then run a detection algorithm on
the resulting coadd.  When the images have different point-spread
functions or noise properties, this method results in needless loss of
sensitivity; producing a coadd effectively forces the use of a
\emph{mismatched filter} rather than a matched filter.  We will show
that the correct procedure involves creating a weighted co-addition of
matched-filtered (smoothed) images.

% Often, astronomers ``co-add'' their imaging to find faint
% objects.  Technically, this step is only justifiable if the bandpass
% and point-spread function are the same for all images, and the images
% ought to be weighted somehow according to sensitivity.  Co-addition is
% not necessary for source detection, of course; it is possible to
% combine low-significance source-detection information coming from many
% images and do as well or better than co-addition.  

% An amusing
% conclusion of this project is that in the principled limit, the
% combination of source-detection information looks very much like a
% (weighted) co-addition of (smoothed) data!

That is, in what follows, we will detect sources as above-threshold
pixels or regions in a weighted co-add of PSF-correlated input images.
We will call this object a ``detection map''.  This detection map is
the best thing to use for source detection.  Once sources are
detected, of course, the detection map should be put aside, and source
properties (positions, colors, and so on) ought to be measured
(inferred) from the raw pixels in the collection of input images via a
likelihood function.  That measurement and likelihood function is
beyond the scope of this paper, but the subject of a parallel research
program (CITE).

\section{Our image model}

We consider astronomical images such as those obtained from an
(idealized) CCD.  Aside from noise, each pixel contains a signal
related to the number of photons incident upon it during the exposure.
We will consider a discrete image made up of a square array of pixels
$\jvec$, each of which has signal (or counts) $C_{\jvec}$, where we
use $\jvec$ as a two-dimensional focal-plane position, measured in
pixel units.  We will assume that the noise (coming from such sources
as the Poisson distribution of the sky background and dark current,
and read noise) is zero-mean, Gaussian, pixelwise independent, and of
known variance.  This assumption is not too bad for sky-limited images
from which the sky level has been subtracted.
We assume that we can estimate the sky level
exactly; in reality our estimate will be noisy.

%  $\psi(\cdot)$ is a function describing the
%pixel-convolved point-spread function of the whole system, and
%$\noise_{\jvec}$ is the noise contribution to pixel $\jvec$.

In the rest of this \doctype, we will assume that the (perhaps tiny)
image of interest contains only a uniform background value plus one
% point source $k$ with some (unknown) flux $F_k$ and position
% $\thetavec_k$.  The pixel-convolved point-spread function of the whole
% system is denoted $\psi(\cdot).
point source with some (unknown) flux and position.  For simplicity we
will assume the source is centered with a pixel.
%The pixel-convolved point-spread function of the whole
% system is denoted $\psi(\cdot)$.
%
For simplicity, we have dropped all assumption-violating contributions
from galaxies, nebulosity, neighboring sources, or sky gradients.

In the above, we have made extremely strong assumptions.  In addition
to the listed assumptions we have assumed that any electronic gain at
readout has been calibrated out.  We have also assumed that the image
is not contaminated by cosmic rays, stray light, bad pixels, bad
columns, electronic artifacts, or any other of the many defects in
real images.

\section{Detecting a point source in a single image}

In this section, we will assume a source $k$ with constant flux $F_k$
and pixel position $\kvec$ (centered within the pixel).  The
image is thus
\begin{eqnarray}
  C_{\jvec} &=& C_k \, \psi(\jvec - \kvec)  + \noise_{\jvec} \quad ,
\end{eqnarray}
where $\psi(\cdot)$ is the (pixel-convolved) point-spread function and
$C_k$ is the total number of counts (summed over pixels) from the
source, which we will call the \emph{source counts}.
We will assume that the point-spread function $\psi(\cdot)$ is
non-negative and, when evaluated on a pixel grid, sums to unity.

% We 
% \begin{eqnarray}\displaystyle
%   S_{\jvec} &\drawnfrom& C_k \, \psi(\jvec - \kvec) + \gaussx{0,\sigma_1^2}
% \label{eq:modelimg}
% \end{eqnarray}
% where the symbol ``$\drawnfrom$'' means ``drawn from the
% distribution'', and $\gaussx{\mu,\sigma^2}$ is the Gaussian
% distribution with mean $\mu$ and variance $\sigma^2$.  Put simply, in
% our model the image pixels contain signal due to a pixel-convolved
% point-spread function $\psi(\cdot)$ shifted to the source center
% $\kvec$ and scaled by the source counts $C_k$; plus additive,
% pixelwise-independent, constant-variance Gaussian noise.  We will
% assume that the point-spread function $\psi(\cdot)$ is non-negative
% and, when evaluated on a pixel grid, sums to unity.  See
% \figref{fig:image}.


\subsection{Optimal linear detection}

In \appref{app:lindet}\ we show that \emph{correlating} an image by
its PSF results in an optimal detector for isolated point sources.

We define the \emph{\detmap} $D_{\jvec}$ as the correlation of
the image with its PSF model, scaled to be in convenient units:
\begin{equation}
D_{\jvec} = \frac{1}{\psfnorm^2} \sum_{\iina} \psfat{\ivec} \, S_{\ivec + \jvec} \quad ,
\label{eq:detmap}
\end{equation}
where $\mathcal{A}$ is the support of the PSF and
$\psfat{\ivec} = \psf(\ivec)$ is an image of the PSF evaluated at
integer-offset pixel positions $\ivec$.  The PSF norm $\psfnorm$ is
\begin{equation}
\psfnorm = \sqrt{\sum_{\iina} \psfat{\ivec}^2} \quad ,
\end{equation}
and as shown in \appref{app:gaussnorm}, a Gaussian PSF with standard
devation $\psfw$ pixels has a norm approximately:
\begin{equation}
  \norm{\bm{\psf^G}} \simeq \frac{1}{2 \sqrt{\pi} \psfw} \quad .
\end{equation}
The per-pixel error in the \detmap\ is given by
\begin{equation}
\sigma_{D} = \frac{\sigma_1}{\psfnorm} \quad .
\end{equation}


We have scaled the \detmap\ so that each pixel contains the
maximum-likelihood total counts of a source centered at that pixel.
That is, computing at pixel $\jvec$ the total source counts
$C^{\ast}_{\jvec}$ to minimizes the chi-squared ($\chi^2$) residual
within the support of the PSF:
\begin{equation}
  C^{\ast}_{\jvec} = \arg\min_{c} \sum_{\ivec} \left( \frac{S_{\ivec+\jvec} - c \, \psi_{\ivec}}{\sigma_1} \right)^2
\end{equation}
we find
\begin{eqnarray}
  C^{\ast}_{\jvec} &=& \frac{\sum_{\ivec} S_{\ivec+\jvec} \, \psi_{\ivec}}{\sum_{\ivec} \psi_{\ivec}^2}
  \\
  C^{\ast}_{\jvec} &=& D_{\jvec} %\quad .
\end{eqnarray}
as defined above.
%
That is, a significant peak in the \detmap\ indicates the likely
position of a point source, and the value of the \detmap\ at a pixel
is the maximum-likelihood estimate of the total source counts for a
source centered at that pixel.
%Recall that we have assumed that the
%image contains only a single isolated point source.


The intuition behind creating a \detmap\ is that the point-spread
function spreads the signal from a point-source over a number of
pixels.  By correlating with the PSF, we ``gather up'' that spread-out
signal, weighting the pixels over which the signal has been spread by
the fraction of the signal that went into each pixel.  By scaling the
\detmap\ by the inverse PSF norm, we convert it to units of total
source counts; this will make it easier to combine \detmap s in what
follows.

% The signal-to-noise in the detection map at the true source pixel
% position $\kvec$ is
% \begin{equation}
% \snr{D_{\kvec}} = \frac{C_k \, \norm{\bm{\psi}}}{\sigma_1} \quad .
% \end{equation}


\subsection{Comments}

\paragraph{Convolution.}  It is common to hear the statement
that \emph{convolving} an image by its PSF model yields an optimal
detection filter.  This is only true if the PSF is defined to be
``flipped'' in both axes relative to the image coordinate system.  We
prefer to define the PSF in unflipped coordinates, so correlation
rather than convolution is the correct operation (they are equivalent
when the PSF model is symmetric).

% \paragraph{Multiple sources.}
% We emphasize that we focus on detecting \emph{isolated point sources}
% in this \doctype.  In particular, we are ignoring important
% practicalities such as blended sources


% -- Sub-pixel peak location...

\paragraph{Peaks.}  We have not yet said anything about \emph{how} to
detect peaks at integer pixel or sub-pixel locations; we discuss this
in \ref{XXX}.


\paragraph{Sufficient statistic.}  Correlation by the PSF ``gathers
up'' all relevant information regarding the presence of a source at
each pixel.  In some astronomical source detection packages (including
SourceExtractor), there is a notion of requiring more than one
neighboring pixel to exceed a detection threshold.  This is not
necessary or useful; in effect it imposes a larger detection threshold
that varies based on the source and PSF morphology.


\section{Detecting a point source in multiple images}

Assume we have a point source whose flux is constant over time, and a
series of images taken through different bandpass filters and with
different noise levels, exposure times, point-spread functions, and
telescope pointings.  We can achieve optimal detection of the source
by building a \detmap\ for each image and combining them with weights
as described below.



\subsection{Identical bandpass filters}

We first present the simpler case where all the images are taken
through identical bandpass filters.

As we have seen, the \detmap\ defined in \eqnref{eq:detmap} is a
maximum-likelihood estimate of the total \emph{counts} contributed by
the source, in the arbitrary units of the original image.  In order to
combine information from multiple images, we must calibrate them so
that they are in the same units.  Since this calibration is simply a
linear scaling, it can be applied to the original image or to the
\detmap.  Similarly, if the images are on different pixel
grids---either from different pointings of the same CCD, or from
different CCDs---then we must \emph{resample} the \detmap s to a
common pixel grid.
%
If the original image is well-sampled, then the \detmap\ (which has
been further smoothed by PSF correlation) will also be well-sampled,
so resampling to a pixel grid of the same or finer resolution results
in no loss of information.
%
Since the pixel values in the \detmap\ represent the \emph{total} flux
from the source, the \detmap\ does not need to be rescaled after
resampling.


Once the \detmap\ for each image has been calibrated and resampled to
a common pixel grid, we have multiple \emph{independent}
maximum-likelihood estimates of the source flux in our chosen filter,
each with a known standard deviation and Gaussian statistics.  That
is, we have multiple Gaussian likelihood functions that we wish to
combine.  Since they are independent, the combined likelihood is the
product of the individual likelihoods.  For Gaussian distributions,
the resulting aggregate maximum likelihood estimate is simply the
inverse-variance-weighted sum of the individual estimates.

If the calibration factor $\kappa_i$ scales image $i$ to flux in
common units, and $R_i$ represents resampling to the common pixel grid,
then the flux estimate $E_i$ is
\begin{eqnarray}
E_i &=& R_i(\kappa_i \, D_i)
\end{eqnarray}
with per-pixel error
\begin{eqnarray}
\sigma_{E, i} &=& \frac{\kappa_i \, \sigma_{1,i}}{\psfnorm_i}
\end{eqnarray}
and we combine the estimates from multiple images via
\begin{eqnarray}
E^{\star} &=& \frac{\displaystyle\sum_i E_i \, \sigma^{-2}_{E,i}}{\displaystyle\sum_i \sigma^{-2}_{E_i}}
\label{eq:onebandmap}
\end{eqnarray}
which has per-pixel error
\begin{eqnarray}
\sigma_{E, \star} &=& \left( \sum_i \sigma^{-2}_{E,i} \right)^{-\frac{1}{2}}    \quad .
\end{eqnarray}
This is simply the maximum-likelihood estimate of the flux based on a
set of independent Gaussian estimates.


\subsection{Different bandpass filters}

As we saw in the single-bandpass case, we can combine multiple
individual exposures into an aggregate estimate of the flux of a point
source.  In order to do this, it was essential to calibrate the images
so that each one is an estimate of the same underlying quantity.  The
multiple-bandpass case is similar: We first combine all the images
taken in each bandpass into a single estimate for that bandpass.
Then, to combine the bandpasses we must scale them so that they are
estimates of the same quantity.  This requires \emph{knowing} the
spectral energy distribution, or at least the \emph{colors} in the
filters of interest, of the source to be detected; this allows us to
scale the various bandpasses so that they are estimates of a common
quantity: perhaps the flux in a canonical band, or some other linear
quantity such as the integrated intensity.

%% FIXME -- does that make sense?  Apparent brightness?  Apparent
%% luminosity?  I just want to say, you could measure it in anything
%% linear, like W/m^2/sr/s or, heck, the projected area of a star of a
%% given temperature)


The intuition here is that if we know that our sources of interest are
twice as bright in bandpass A than in bandpass B, then we can convert
an estimate of the brightness in band B into an estimate of the
brightness in band A by multiplying by two.  The variance of the
scaled estimate increases appropriately, so a bandpass in which a
source is expected to be faint will contribute an estimate with a
large variance and will be downweighted when the estimates are
combined.  We can also view the problem as one of estimating a
``total'' flux that has been split into the different bandpasses, and
in that view it is analogous to the way flux is spread into pixels by
the point-spread function.

\newcommand{\sigdj}{\sigma_{j}}

Assume we have detection maps $D_j$, with per-pixel standard deviation
$\sigdj$ for a number of different bandpasses.  Assume each
bandpass has a known conversion factor $f_j$ to the canonical band;
that is,
\begin{eqnarray}
  D_j & \drawnfrom & \gaussx{f_j \, C, \sigdj^2}
\end{eqnarray}
for flux in the canonical band $C$.  Given a number of such detection
maps, we assume they are independent and find that the
maximum-likelihood estimate for $C$ is:
\begin{eqnarray}
  \hat{C} &=& 
  \frac{\sum_j D_j \, f_j \, \sigdj^{-2}}%
       {\sum_j f_j^2 \, \sigdj^{-2}}
\end{eqnarray}
with per-pixel error
\begin{eqnarray}
  \hat{\sigma}_C &=& \left( \sum_j f_j^2 \sigdj^{-2} \right)^{-\frac{1}{2}}
  \quad .
\end{eqnarray}


For example, if we treat $r$ band as the canonical band and our
objects of interest have color $r-i = 1$, then we will scale our
$i$-band detection map $D_i$ by $f_i = (2.5)^{-(r-i = 1)}$; the
sources are expected to be brighter in $i$ band so we must \emph{scale
  down} the $i$-band estimate to produce an $r$-band estimate.  The
$i$-band variance is also reduced in a corresponding way, so this does
not dilute the weight of high-precision measurements.




\section{Experiments}

\subsection{Sloan Digital Sky Survey}

Here we present some proof-of-concept experiments on Sloan Digital Sky
Survey (SDSS) data from the Stripe 82 region \cite{sdss}.

% FIXME -- The results show XYZ...

\paragraph{Input data selection.}
We select input exposures to include as follows.  Using the
``window\_flist'' table for SDSS Data Release 9 \cite{dr9}, we select
photometric exposures from camera column 3, with RA in the range
$[45.15, 45.85]$ and Dec in the range $[-0.2, -0.1]$.  This results in
$109$ fields from $23$ unique runs, which are listed in
\tabref{tab:fields}.

\paragraph{\Detmap\ and resampling.}
For each input image, we take the PSF to be the double-Gaussian model
computed by the SDSS \emph{Photo} pipeline \cite{photo}, and compute
the \detmap.  Since SDSS DR9 images are already in sky-subtracted,
calibrated ``nano-maggies'', we do not need to apply a calibration
factor to convert them to common units, nor do we need to remove a sky
background level.  We set to zero any image pixels that are masked as
saturated, interpolated, cosmic ray, ghost, or ``not checked'' (close
to the image boundaries).
% 'INTERP', 'SATUR', 'NOTCHECKED', 'GHOST', 'CR'
We compute the per-pixel noise ($\sigma_1$) based on a Gaussian
approximation of the Poisson errors from the mean sky level, plus dark
current and read noise, as recommended by the SDSS
team.\footnote{\niceurl{http://data.sdss3.org/datamodel/files/BOSS\_PHOTOOBJ/frames/RERUN/RUN/CAMCOL/frame.html}}


For each of the $u$, $g$, $r$, $i$ and $z$ bandpass filters
(``bands''), we resample to a common pixel grid and then compute a
per-band \detmap\ as per \eqnref{eq:onebandmap}.  The common pixel
grid is defined by a WCS tangent-plane projection centered on our
patch of interest with the nominal SDSS pixel scale (0.396 arcseconds
per pixel) and image size $4096 \times 2048$ \cite{wcs}.  Since the
SDSS pipeline adds a 128-pixel overlap between neighboring fields in a
run, we first build a \detmap\ for each run, averaging values in the
overlapping regions to avoid double-counting, then combine these
per-run \detmap s as per \eqnref{eq:onebandmap}.  For resampling we
use a third-order Lanczos kernel.

% We track the inverse-variance on a per-pixel basis

\paragraph{Background correction.}
We find that there is considerable spatially-coherent structure in our
combined \detmap s, which we suspect is due to slightly biased
background subtraction in the SDSS pipeline code.  We estimate and
remove a residual background as follows.  After masking all pixels
above 5 sigma, we compute the
median value within each cell of a $\sim 100 \times 100$-pixel grid,
and interpolate between these values with a third-order B-spline.  The
resulting background-subtracted \detmap s have no apparent background
structure and their pixel distributions are closer to Gaussian.  See
\figref{fig:bg}.

\paragraph{Detection}
In this \doctype\ we are not concerning ourselves with blended
objects, so we identify peaks in the \detmap\ naively.  We find
pixels above the desired threshold, expand by a 2-pixel radius, and
find the connected components.  For each component, we return the peak
pixel, ignoring other peaks within the component.


We construct a series of spectral energy distributions (SEDs),
building the combined \detmap\ and running the peak detection
algorithm for each.  A standard approach for detecting objects in
imaging from multiple bands is to weight each band by its
signal-to-noise.  This is equivalent to assuming a flat spectrum, or
zero color.  Our SED-matched filters weight each band according to
both the amount of flux we expect to see in the band, and its
signal-to-noise.  The SEDs we use here include ``Flat'' (expected
color $g = r = i$), ``Red'' ($g-r = r-i = 1$), ``Blue'' ($g-r = r-i =
-1$), and four points lying approximately along the stellar locus
($(g-r, r-i)$ colors $(0.5,0.2)$, $(1.0,0.4)$, $(1.4,0.7)$, and
$(1.4,1.4)$.  In the experiments here we will compare the detection
strengths in the different SEDs.  In practice we would return the
union of peaks detected in this way.



% XXX: Verify this statement
% XXX: Cite ``standard approach''
% XXX: Advice on what to do in practice?

\paragraph{Results}
In \figref{fig:redblue} we show that objects with red colors in the
SDSS catalog are detected more strongly by our SED-matched Red filter
than a Flat SED (which corresponds to the traditional multi-band
detection approach).  There are very few objects that the Blue
SED-matched filter detects more strongly than the Flat or Red filters;
astrophysical objects with very blue colors are rare.

In \figref{fig:colorcolor} we show, in color-color space, the sources
detected by each of our SED-matched filters.  As expected, each filter
is most sensitive to sources in a given region of color-color space.

% FIXME -- show strongest detections for each SED.

In \figref{fig:missed} we show postage-stamp images of sources that
are detected by our SED-matched filters and not detected by a
traditional approach.  In \figref{fig:added} we show in color-color
space the additional objects that are detected as we apply a sequence
of SED-matched filters.



\subsection{Simulations}

---Single exposure, single band

---Multiple exposures (different PSFs, sky), single band

---Multiple exposures, multiple bands









\begin{table}
\begin{center}
\begin{tabular}{|r|r|r|}
\hline
Run & Min field & Max field \\
\hline
1752 & 163 & 166 \\
1887 & 107 & 111 \\
2578 & 112 & 116 \\
2589 & 200 & 204 \\
2700 & 168 & 171 \\
2738 & 220 & 224 \\
2820 & 168 & 172 \\
2861 & 86 & 90 \\
2873 & 211 & 215 \\
3362 & 169 & 173 \\
3384 & 671 & 675 \\
3461 & 20 & 24 \\
4128 & 425 & 429 \\
4157 & 178 & 181 \\
4198 & 664 & 668 \\
4207 & 673 & 677 \\
4849 & 757 & 760 \\
4858 & 656 & 660 \\
4874 & 723 & 727 \\
4905 & 304 & 307 \\
4927 & 654 & 658 \\
4933 & 665 & 668 \\
4948 & 245 & 249 \\
\hline
\end{tabular}
\caption{SDSS fields included in the experiments.  All fields are from
  camera column (``camcol'') 3.  The minimum and maximum (inclusive)
  fields are listed.\label{tab:fields}}
\end{center}
\end{table}



\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{detect-r-00} \\
\includegraphics[width=0.7\textwidth]{detect-r-01} \\
\includegraphics[width=0.8\textwidth]{detect-r-02}
\caption{Residual background subtraction.  \textbf{Top:} combined
  \detmap\ for the SDSS $r$ band, combining images from 23 runs.
  There are clear patterns in the background level.  \textbf{Middle:}
  after estimating and removing the residual background as described
  in the text, the background appears more flat.  \textbf{Bottom:}
  after removing the background, the pixel error statistics are closer
  to Gaussian, though the distribution is still significantly
  broader than expected.\label{fig:bg}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-11}
\caption{Detection strengths in the Red, Flat, and Blue SED-matched
  filters, versus SDSS-measured colors.  We performed a spatial match
  between our detected sources and SDSS sources (from the DR7 CasJobs
  database ``Stripe82''; \cite{annis}) within 1 pixel.  Redder objects
  in $g-i$ are detected more strongly in the Red SED-matched filter
  than Flat or Blue.  The handful of objects with significantly blue
  colors are detected more strongly with the Blue filter.
  \label{fig:redblue}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-17}
\caption{Color-color space locations of sources detected most strongly
  by each of the filters.
  The color measurements are from the SDSS
  Stripe82 coadd catalog \cite{annis}, matched to
  our detections using a 1-pixel matching radius.
  It is clear that
  our different SED-matched filters are tuned to detect objects in
  particular regions of color-color space.  The ``X'' marks indicate
  the color each SED-matched filter is tuned for.  Note that many of
  the sources are detected above a given detection threshold by
  several of the SED-matched filters; here each source is assigned to
  the filter by which it is detected most strongly.
  \label{fig:colorcolor}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-14}
\includegraphics[width=0.8\textwidth]{mdetect-15}
\includegraphics[width=0.8\textwidth]{mdetect-16}
\caption{Sources detected by our SED-matched filters and not by a
  ``traditional'' approach; full caption on next page\label{fig:missed}}
\end{center}
\end{figure}

\addtocounter{figure}{-1}
\begin{figure}
\begin{center}
\caption{[figure previous page] Sources detected by applying a
  sequence of SED-matched filters.  We start with sources detected by
  a ``traditional'' approach that takes the union of single-band
  detections in each of the $g$, $r$, and $i$ filters.  We then apply,
  in sequence, our Flat, Red, and Stellar locus SED-matched filters.
  Each panel shows the sources detected by the new filter and not
  detected by previous filters, in order of decreasing
  signal-to-noise.  In order to make the objects easier to see, we
  have increased the detection threshold to $20 \sigma$.}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-18}
\caption{Color-color space locations of additional sources detected as
  additional SED-matched filters are applied.  We start by taking all
  single-band detections in the $g$, $r$, and $i$-band filters.  Next,
  we add sources detected by the Flat SED-matched filter, then the Red
  filter, then a set of filters along the stellar locus.  Each
  subsequent SED-matched filter detects sources that are missed (at a
  fixed detection threshold) by the previous filters.
  %The color measurements are from the SDSS
  %Stripe82 coadd catalog \cite{annis}, matched to
  %our detections using a 1-pixel matching radius.
  \label{fig:added}}
\end{center}
\end{figure}






\end{document}

