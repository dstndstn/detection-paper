\documentclass[letterpaper,preprint]{aastex62}
\usepackage{bm}
\usepackage{calc}
\usepackage{amssymb, amsmath}
\usepackage{hyperref}
\newcounter{address}
\newcommand{\doctype}{paper}
\newcommand{\equationname}{equation}
\newcommand{\eqnref}[1]{\mbox{\equationname~\ref{#1}}}
\newcommand{\appref}[1]{\mbox{Appendix~\ref{#1}}}
\newcommand{\Appref}[1]{\mbox{Appendix~\ref{#1}}}
\newcommand{\tabref}[1]{\mbox{Table~\ref{#1}}}

\newcommand{\niceurl}[1]{\mbox{\href{#1}{\textsl{#1}}}}

\newcommand{\latin}[1]{\emph{#1}}
\newcommand{\etal}{\latin{et\,al.}}
\newcommand{\ie}{\latin{i.e.}}
\newcommand{\apriori}{\latin{a priori}}
\newcommand{\sn}{{[s/n]}}
\newcommand{\sntotal}{\sn_{\mathrm{total}}}
\newcommand{\fwhm}{{\theta_{\mathrm{FWHM}}}}
\newcommand{\RA}{{\mathrm{RA}}}
\newcommand{\Dec}{{\mathrm{Dec}}}
\newcommand{\vecmu}{\bm{\vec{\mu}}}
\newcommand{\mualpha}{{\mu_\alpha}}
\newcommand{\mudelta}{{\mu_\delta}}
\newcommand{\var}[1]{\mathrm{Var}({#1})}
\newcommand{\unit}[1]{\mathrm{#1}}
\renewcommand{\mag}{\unit{mag}}
\newcommand{\s}{\unit{s}}
\newcommand{\yr}{\unit{yr}}
\newcommand{\km}{\unit{km}}
\newcommand{\pc}{\unit{pc}}
\newcommand{\kpc}{\unit{kpc}}
\newcommand{\mas}{\unit{mas}}
\newcommand{\pix}{\unit{pix}}
\newcommand{\kmpers}{\km\,\s^{-1}}
\newcommand{\masperyr}{\mas\,\yr^{-1}}
\renewcommand{\arcsec}{\unit{arcsec}}
\newcommand{\arcsecperyr}{\arcsec\,\yr^{-1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\mean}[1]{\left<{#1}\right>}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\figpart}[1]{\textbf{#1}}
%\newcommand{\fig}{Figure}
%\newcommand{\figref}[1]{\mbox{\fig~\ref{#1}}}
\newcommand{\figref}[1]{\mbox{Figure~\ref{#1}}}
\newcommand{\detmap}{detection map}
\newcommand{\Detmap}{Detection map}
\newcommand{\fluxmap}{flux map}
\newcommand{\fmap}{F}
\newcommand{\drawnfrom}{\sim}
\newcommand{\gaussianN}{\mathcal{N}}
\newcommand{\gaussian}[1]{\gaussianN\!\left(#1\right)}
%\newcommand{\gaussx}[2]{\hat{\gaussianN}\!\left(#1 \, , \, #2\right)}
\newcommand{\gaussx}[2]{\gaussianN\!\left(#1 \, , \, #2\right)}
%\newcommand{\gaussx}[1]{\mathfrak{N}\!\left(#1\right)}
%\newcommand{\psf}{\mathrm{psf}}
\newcommand{\psf}{\psi}
\newcommand{\psfat}[1]{\psf_{#1}}
\newcommand{\psfnorm}{\norm{\bm{\psf}}}

\newcommand{\signoise}{[S/N]}
\newcommand{\snr}[1]{\mathbb{SN}(#1)}
%\newcommand{\snr}[1]{\mathcal{SN}(#1)}

\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\expect}[1]{\left\langle #1 \right\rangle}
\renewcommand{\var}[1]{\mathrm{var}\left( #1 \right)}
\newcommand{\sky}{\mathrm{sky}}
\newcommand{\psfw}{w}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\noise}{e}
\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\thetavec}{\vec{\theta}}
\newcommand{\avec}{\vec{a}}
\newcommand{\ivec}{\vec{i}}
\newcommand{\jvec}{\vec{j}}
\newcommand{\kvec}{\vec{k}}
\newcommand{\cvec}{\vec{c}}
\newcommand{\posvec}{\vec{x}}
\newcommand{\coord}[2]{(#1, #2)}
\newcommand{\iina}{\ivec \,\, \mathrm{in} \,\, \mathcal{A}}

\newcommand{\erf}{\textrm{erf}}

\begin{document}
\title{Principled point-source detection in collections of astronomical images}
\author{Dustin Lang}
%\altaffiliation{To whom correspondence should be addressed; \texttt{dstndstn@gmail.com}}
\affiliation{%
  Dunlap Institute and Department for Astronomy \& Astrophysics,
  University of Toronto,
  50 Saint George Street, Toronto, ON, M5S 3H4, Canada}
\affiliation{%
  Visitor, Department of Physics \& Astronomy,
  University of Waterloo,
  200 University Avenue West, Waterloo, ON, N2L 3G1, Canada}
\affiliation{%
  Visitor, Perimeter Institute for Theoretical Physics,
  31 Caroline Street North, Waterloo, ON, N2L 2Y5, Canada}

\author{David W. Hogg}
\affiliation{%
  Center for Cosmology and Particle Physics,
  Department of Physics,
  New York University, 4 Washington Place, New York, NY 10003, USA}
\affiliation{%
  Max-Planck-Institut f\"ur Astronomie,
  K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\correspondingauthor{Dustin Lang}
\email{dstndstn@gmail.com}

\begin{abstract}
We review the well-known \emph{matched filter} method for the
detection of point sources in astronomical images.  This is shown to
be optimal (that is, to saturate the Cram\'er--Rao bound) under stated
conditions that are very strong: an isolated source in
background-dominated imaging with perfectly known background level,
point-spread function, and noise models.  We show that the matched
filter produces a maximum-likelihood estimate of the brightness of a
purported point source, and this leads to a simple way to combine
multiple images---taken through the same bandpass filter but with
different background levels and point-spread functions---to produce an
optimal point source detection map.  We then extend the approach to
images taken through different bandpass filters, introducing the
\emph{SED-matched filter}, which allows us to combine images taken
through different filters, but requires us to specify the colors of
the objects we wish to detect.  We show that this approach is superior
to some methods traditionally employed, such as the \emph{chi-squared
  coadd} (Szalay \emph{et al.} 1999), and that other traditional
methods can be seen as instances of SED-matched filtering with implied
(and often unreasonable) priors.
%
% We suggest a set of SED filters and how one ought to proceed: lower
% the detection threshold to ensure that all sources of interest are
% detected, then fit for their properties and keep or discard sources
% based on their utility for the question at hand.
%
\end{abstract}

\keywords{
    methods:~statistical ---
    techniques:~image~processing
}


\section{Introduction}


FIXME -- are we going to talk about detecting galaxies?  Seems like we
should!

FIXME -- should we talk about the probability of selecting the wrong
pixel as the peak?

FIXME -- need some consistent way of labelling image quantities, and
sensible naming and careful use of ``flux'' and ``counts''.  Some
notation for ``estimates for'' or ``maximum-likelihood point estimate
of'' would be useful too.  Hats?

FIXME -- Szalay+1999 actually talk about SED-matched detection!!
Section 4.2, and they call it ``optimal subspace filtering''.


There are few operations in astronomy more important than the
detection of stars or point sources.
Indeed, many astronomical discoveries come down to point-source
detection.
What is the best method for performing such detection?
Here we answer that question, in the limited context of isolated
sources, uniform sky-limited noise, and well-understood point-spread
function.
Even in this limited context, the subject is rich and valuable; more
general---and more difficult---cases will be illuminated if we can
understand the simplest case first.

Fundamentally, when much is understood about a signal latent in noisy
data, the best detection methods are (or look like) \emph{matched
filters}.
A matched filter is a model of the expected signal with which the data
are \emph{cross-correlated}. % (often wrongly called ``convolved'').
Peaks in the cross-correlation are candidate signal detections.
In point-source detection in astronomical images, the expected signal is the
point-spread function (PSF), and the cross-correlation operation is often
wrongly called ``convolution by the PSF''.
Matched filters are well used in astronomy, in contexts ranging from
spectroscopy (CITE) to
galaxy clusters \cite{redmapper, melin} to
ultra-faint galaxies \cite{willman1} to
exoplanets \cite{exoplanet} to
gravitational radiation \cite{ligo}.

% from the tweeps:
% http://scholar.google.com/scholar?q=astronomy+matched+filter
% http://arxiv.org/abs/astro-ph/0602424

In what follows, we will argue for matched filtering for point-source
detection.  This is not new (CITE); what is new is that we consider
the common context of heterogeneous (in point-spread function and
sensitivity) multi-epoch, multi-band imaging.
%
While the optimality of matched filtering for single-image point
source detection is well known by astronomers, the straightforward
mathematics behind it is often not, leading to a misconception that
it is simply an algorithmic choice.  To our knowledge, the optimal%
\footnote{In this \doctype\ we use ``optimal'' in a technical sense,
 of saturating the Cram\'er--Rao bound under stated assumptions.  We
 encourage other authors to do the same!}
method of combining multiple images with different properties to
obtain the greatest possible sensitivity to point sources has not been
written down in the astronomical literature.  The mathematics are
straightforward and the resulting procedure is simple and
computationally inexpensive.  

Perhaps more controversially, we go on to argue that when imaging in
multiple bands is available, one should again use a matched filter,
now matched to the spectral-energy distribution (SED) of the sources
to be detected.  This SED-matched filtering, as we will call it, makes
explicit the assumptions that are implicitly embedded in any method
that attempts to detect sources by combining imaging from multiple
bands.

In the Real World, astronomers never precisely know their point-spread
function, their noise model, their flat-field (or other calibration
parameters), nor the spectral-energy distributions of the sources of
greatest interest.
Also, often, the sources of interest aren't point sources or perhaps
vary with time.
In these cases, we advocate parameterizing ignorance, and operating
with the union of all possibly appropriate matched filters.
We will fully execute this idea here when it comes to spectral-energy
distributions, but there are natural extensions to deal with
point-spread function, noise-model, calibration, and time-domain
uncertainties.

% FIXME -- DISCUSS each of the things listed above in the Discussion (or omit)!



A ``traditional'' approach for detecting sources in multi-epoch
imaging is to co-add the images and then run a detection algorithm on
the resulting coadd.  When the images have different point-spread
functions or noise properties, this method results in needless loss of
sensitivity; producing a coadd effectively forces the use of a
\emph{mismatched filter} rather than a matched filter.  We will show
that the correct procedure involves creating a weighted co-addition of
matched-filtered (smoothed) images.

% Often, astronomers ``co-add'' their imaging to find faint
% objects.  Technically, this step is only justifiable if the bandpass
% and point-spread function are the same for all images, and the images
% ought to be weighted somehow according to sensitivity.  Co-addition is
% not necessary for source detection, of course; it is possible to
% combine low-significance source-detection information coming from many
% images and do as well or better than co-addition.  

% An amusing
% conclusion of this project is that in the principled limit, the
% combination of source-detection information looks very much like a
% (weighted) co-addition of (smoothed) data!

That is, in what follows, we will detect sources as above-threshold
pixels or regions in a weighted co-add of PSF-correlated input images.
We will call this object a ``detection map''.  This detection map is
the best thing to use for source detection.  Once sources are
detected, of course, the detection map should be put aside, and source
properties (positions, colors, and so on) ought to be measured
(inferred) from the raw pixels in the collection of input images via a
likelihood function.  That measurement and likelihood function is
beyond the scope of this paper, but the subject of a parallel research
program (eg, \cite{unwise-phot}).

\section{Our image model}

We consider idealized astronomical images such as those obtained from
a CCD in typical broadband optical imaging.
Specifically, we will make the following strong assumptions:
\begin{itemize}
\item the noise (coming from such sources as the Poisson distribution
  of the sky background, dark current, and read noise) is zero-mean,
  Gaussian, pixelwise independent, and of known constant variance.  The
  zero-mean assumption can be seen as assuming perfect background
  subtraction (sky estimation);
\item the image is well sampled;
\item the (perhaps tiny) image contains \emph{only} one point
  source with some (unknown) flux and position;
\item the source is centered within a pixel (we will relax this
  later);
\item the point-spread function is spatially constant (across the
  possibly small image patch of interest) and known perfectly;
\item the device is linear and the photometric calibration of the
  image is known perfectly; that is, that it is possible to map from
  ``count'' units back to physical units or a photometric standard;
\item the image is perfectly astrometrically calibrated;
\item the image is not contaminated by cosmic rays, stray light, bad
  pixels, bad columns, electronic artifacts, or any other of the many
  defects in real images.
\end{itemize}

Throughout this \doctype\ we assume a ``pixel-correlated'' PSF; we
consider the point-spread function to \emph{include} the effects of
pixelization.  In well-sampled images, we think of the image as being
a continuous function which, after being correlated by the PSF, is
sampled at delta-function pixel locations.  There is no need to think
of pixels as ``little boxes''; they are simply samples of an
underlying smooth two-dimensional signal.

% FIXME -- mention that the pixel-sampled PSF is the thing we actually
% have access to in the images. (ie, if we use known stars to construct
% a PSF model)


With these strong assumptions, we can write down the probability
distribution of each pixel value, which allows us to prove the
optimality of the methods we present.
%
We will consider a discrete image made up of a square array of pixels
$\jvec$, each of which has value $I_{\jvec}$, where we
use $\jvec$ as a two-dimensional focal-plane position, measured in
integer pixel units.
%
If the image contains a single point source, centered on
the pixel at position $\kvec$ and with constant flux resulting in a
total number of counts $F$, then the image is
\begin{eqnarray}
  I_{\jvec} &=& F \, \psfat{\jvec - \kvec} + \noise_{\jvec} \quad ,
  \label{eqn:image}
\end{eqnarray}
where $\psi(\jvec-\kvec)$ is the point-spread function evaluated at
offset $\jvec-\kvec$ and $\noise_{\jvec}$ is per-pixel noise drawn
from a zero-mean Gaussian with known, constant, per-pixel variance $\sigma_1^2$.
%
We can also write this as
\begin{eqnarray}
  I_{\jvec} &\drawnfrom& \gaussx{F \, \psfat{\jvec - \kvec}}{\sigma_1^2}
  \quad ,
\end{eqnarray}
meaning that $I_{\jvec}$ is drawn from a Gaussian distribution with
mean $F\, \psf(\jvec - \kvec)$ and variance $\sigma_1^2$.


\section{Detecting a point source in a single image}

%\subsection{Optimal linear detection}

Here we consider a point source $k$ in a single image, as in
\eqnref{eqn:image}.

% the map $M_{\jvec}$ can
% be computed by correlating the image with its PSF:
% \begin{equation}
% M_{\jvec} = \sum_{\iina} \psi_{\ivec} \, S_{\ivec + \jvec} \quad ,
% \end{equation}
% where, as before, $\mathcal{A}$ is the support of the PSF and
% $\psfat{\ivec} = \psi(\ivec)$ is an image of the PSF evaluated at
% integer pixel positions $\ivec$.

The \emph{matched filtering} operation, also known as ``smoothing by
the PSF'' or ``correlating by the PSF''\footnote{
  Or, often, ``convolving by the PSF'', being slightly careless with terminology.}
can be written as
\begin{eqnarray}
  M_{\jvec} &=& \sum_{\iina} \psfat{\ivec} \, I_{\ivec + \jvec} \quad ,
\end{eqnarray}
where $\mathcal{A}$ is the support of the PSF and $\psfat{\ivec} =
\psf(\ivec)$ is an image of the PSF evaluated at integer pixel
positions $\ivec$.  This operation can be seen as ``gathering up'' the
signal that is dispersed into many pixels by the PSF, weighting by the
fraction of the flux that went into the pixel.  In
\appref{app:lindet} we derive the matched filter and show that it
saturates the Cram\'er--Rao bound.

% In \appref{app:lindet}\ we show that \emph{correlating} an image by
% its PSF---\emph{matched filtering}---results in an optimal detector
% for isolated point sources.  This operation can be seen as ``gathering
% up'' the signal that is dispersed into many pixels by the PSF; or as
% re-scaling each pixel in the support of the PSF into an estimate of
% the total flux and producing a weighted average of these estimates.

We define the \emph{\detmap} $D_{\jvec}$ as the matched filter, scaled to be in convenient units:
\begin{equation}
D_{\jvec} = \frac{1}{\psfnorm^2} \sum_{\iina} \psfat{\ivec} \,
I_{\ivec + \jvec} \quad ,
\label{eq:detmap}
\end{equation}
%where $\mathcal{A}$ is the support of the PSF and
%$\psfat{\ivec} = \psf(\ivec)$ is an image of the PSF model evaluated at
%integer-offset pixel positions $\ivec$.
The PSF norm $\psfnorm$ is
\begin{equation}
\psfnorm = \sqrt{\sum_{\iina} \psfat{\ivec}^2} \quad ,
\end{equation}
and as shown in \appref{app:gaussnorm}, a Gaussian PSF with standard
devation $\psfw$ pixels has a norm approximately:
\begin{equation}
  \norm{\bm{\psf^G}} \simeq \frac{1}{2 \sqrt{\pi} \psfw} \quad .
\end{equation}
The per-pixel error in the \detmap\ is given by
\begin{equation}
\sigma_{D} = \frac{\sigma_1}{\psfnorm} \quad .
\end{equation}


We have scaled the \detmap\ so that each pixel contains the
maximum-likelihood estimate of the total counts of a source centered
at that pixel.  That is, if we compute at pixel $\jvec$ the total
source counts $F^{\ast}_{\jvec}$ to minimizes the chi-squared
($\chi^2$) residual within the support of the PSF:
\begin{equation}
  F^{\ast}_{\jvec} = \arg\min_{f} \sum_{\ivec} \left( \frac{I_{\ivec+\jvec} - f \, \psfat{\ivec}}{\sigma_1} \right)^2
\end{equation}
we find
\begin{eqnarray}
  F^{\ast}_{\jvec} &=& \frac{\sum_{\ivec} I_{\ivec+\jvec} \, \psfat{\ivec}}{\sum_{\ivec} \psfat{\ivec}^2}
  \\
  F^{\ast}_{\jvec} &=& D_{\jvec} %\quad .
\end{eqnarray}
as defined above.
%
That is, a significant peak in the \detmap\ indicates the likely
position of a point source, and the value of the \detmap\ at a pixel
is the maximum-likelihood estimate of the total source counts for a
source centered at that pixel.


\subsection{Threshold and Peaks}

% In astronomical imaging, and in particular in large-scale surveys, it

Once we have computed a detection map, we typically wish to produce a
list of detected sources.  Standard practice is to apply a threshold
at, say, $5 \sigma_D$, and accept any peak above that threshold as a
source (or a blended group of sources).\footnote{%
  ``Deblending'' nearby groups of sources is a challenging task that
  is beyond the scope of this paper.}
In regions containing no
sources, the detection map contains Gaussian noise.  Due to the
correlation operation, the detection map pixels are not pixelwise
independent, but as weighted sums of Gaussian samples they remain
Gaussian.  As such, the expected number of pixels above a threshold
$\tau$ is the integral of the high tail of the normal distribution.
For $\tau = 5 \sigma_D$, the fraction of pixels above threshold due to
noise is about $2.9\times10^{-7}$, which seems tiny except that we
will be evaluating millions of pixels; in a 4k$\times$4k image we
would expect approximately $5$ false positive detections.

There is nothing special about $5 \sigma$ as a detection threshold; it
is simply a choice of tradeoff between allowing some false positives
while preventing too many false negatives (lost detections).  In
different situations, higher or lower thresholds could be preferable.

\subsection{Comments}

\paragraph{PSF model}
Computing the detection map requires correlation of the image by a
model of its point-spread function.  In practice, the PSF model is
never known exactly, and since correlation by large pixelized models
can be expensive, it is common to approximate the PSF by a Gaussian
for the purposes of detecting sources.  The impact this approximation
of the PSF has on detection efficiency is apparent in the derivation
of the matched filter; in equation \ref{eqn:psfdotprod}, the detection
map signal-to-noise is proportional to the cosine distance between the
true PSF and the correlation kernel.  In typical ground-based images,
this results in only a few percent loss in signal-to-noise.  For
example, in our Legacy Surveys images, if we assume that our pixelized
model of the PSF is correct, then a Gaussian approximation typically
yields above $97\%$ efficiency.

\paragraph{Biases}
In this paper, we have assumed that backgrounds due to atmospheric
emission (``sky'') and detector effects such as bias and dark current
have been perfectly estimated and subtracted.  In real images,
however, errors in these estimates can leave spatially coherent
residual biases, and these can have a considerable effect on source
detection.  For example, a background that is elevated by $0.05
\sigma_1$ per pixel can double the $5\sigma$ false positive rate in
good seeing, and has an even greater effect in worse seeing.

% Specifically, sky bias on detection:
% D_j / sigma_D = 1/||psf||^2 (\sum_i \psf_i (C_i + b)) / (sigma_1/||psf||)
%               = 1/(||psf|| sigma_1) (\sum_i \psf_i C_i + b)
% if b = \beta \sigma_1, D_j / sigma_D is offset by
%  \beta / ||psf||

% ||psf_G(width = 1)|| ~ 0.282
% so a sky bias of 0.05 sigma per pixel yields a shift of 0.177 sigma;
%
%scipy.special.erfc((5. - 0.05/0.282)/np.sqrt(2.))/2.
%-> 7.081571486838887e-07
% Which is over twice the 5-sigma FP rate.

% Peak statistics in Gaussian fields
% Rice 1944, 1945
% Longuet-Higgins 1957 (2-d)

% scipy.special.erf = 2/sqrt(pi)*integral(exp(-t**2), t=0..z)

% vs normal 1/sqrt(2 pi sigma^2) exp(-(x-mu)^2/(2 sigma^2))

% Fraction in high tail of N(1,0) above tau:
% f = (1.-scipy.special.erf(tau / np.sqrt(2.))) / 2
% f = scipy.special.erfc(tau /np.sqrt(2.))/2.

% 5 sigma:
% scipy.special.erfc(5./np.sqrt(2.))/2.
% 2.866515718791945e-07

% 4.9 sigma: scipy.special.erfc(4.9/np.sqrt(2.))/2.
% 4.791832765903203e-07

% 4.5 sigma: scipy.special.erfc(4.5/np.sqrt(2.))/2.
% 3.3976731247300607e-06



% \paragraph{Convolution.}  It is common to hear the statement
% that \emph{convolving} an image by its PSF model yields an optimal
% detection filter.  This is only true if the PSF is defined to be
% ``flipped'' in both axes relative to the image coordinate system.  We
% prefer to define the PSF in unflipped coordinates, so correlation
% rather than convolution is the correct operation (they are equivalent
% when the PSF model is symmetric).

% \paragraph{Multiple sources.}
% We emphasize that we focus on detecting \emph{isolated point sources}
% in this \doctype.  In particular, we are ignoring important
% practicalities such as blended sources


% -- Sub-pixel peak location...

\paragraph{Sub-pixel peaks}  The detection map defined above
is computed by correlating the image with its PSF, on the image pixel
grid.  As the PSF becomes narrow, the detection efficiency varies
depending on the position of a source within the pixel.  The detection
map is maximized when the image is a scaled version of the PSF
(matched filter), but if the image is shifted within a pixel relative
to the PSF model, then the peak value attained by the detection map is
lower (because the filter is slightly mismatched).  For example, with
a Gaussian PSF with standard deviation of 1 pixel, the detection map
drops as low as 88\% efficiency for a source midway between pixels in
both dimensions.

To reduce this effect, one could compute multiple detection maps,
using for each a different subpixel-shifted versions of the PSF model.
Alternatively, one could lower the detection threshold to compensate,
then fit for the best source position and drop sources with best-fit
values below threshold.


\paragraph{Sufficient statistic}  Correlation by the PSF summarizes
all relevant information regarding the presence of a source at each
pixel; the detection map and its variance are sufficient to describe
our knowledge.  In some astronomical source detection packages
(including SourceExtractor), there is a notion of requiring more than
one neighboring pixel to exceed a detection threshold.  This is not
necessary or useful; in effect it imposes a larger detection threshold
that varies based on the source morphology and PSF, which is
undesirable.


% \paragraph{What would Bayes do?}  FIXME -- We haven't really explained that
% we are producing and evaluating an estimate for each pixel.  Could
% also point out that one could instantiate and test the generative
% model (with position and flux) at each pixel, and that this basically
% just short-cuts that process, telling you places where that test is
% going to give significant results.

\paragraph{Galaxies}
We have focused only on point sources, but the same arguments can be
used to develop a detector for galaxies.  The matched filter by which
the image must be correlated is then the intrinsic galaxy profile
correlated with the PSF; a matched-filtering approach is only optimal
for a given galaxy profile.  As with using an approximation for the
PSF model, the non-optimality due to using an incorrect galaxy profile
is related to the cosine distance between the correct and model galaxy
profile.

In practice, our mixture-of-Gaussians approximations to standard
exponential and deVaucouleurs galaxy profiles \cite{gaussgals} are
convenient for this task.



\section{Detecting a point source in multiple images}

In this section we will assume we have a stationary point source whose
flux is constant over time, and a series of images taken through
different bandpass filters and with different noise levels, exposure
times, point-spread functions, and telescope pointings.  We can
achieve optimal detection of the source by building a \detmap\ for
each image and combining them with weights as described below.



\subsection{Identical bandpass filters}

We first present the simpler case where all the images are taken
through identical bandpass filters.

As we have seen, the \detmap\ defined in \eqnref{eq:detmap} is a
maximum-likelihood estimate of the total \emph{counts} contributed by
the source, in the units of the original image.  In order to
combine information from multiple images, we must calibrate them so
that they are in the same units.  Since this calibration is simply a
linear scaling, it can be applied to the original image or to the
\detmap.  Similarly, if the images are on different pixel
grids---either from different pointings of the same CCD, or from
different CCDs---then we must \emph{resample} the \detmap s to a
common pixel grid.
%
If the original image is well-sampled, then the \detmap\ (which has
been further smoothed by PSF correlation) will also be well-sampled,
so resampling to a pixel grid of the same or finer resolution results
in no loss of information.
%
Since the pixel values in the \detmap\ represent the \emph{total} flux
from a point source, the \detmap\ does not need to be rescaled when
resampled to a different pixel scale.



Once the \detmap\ for each image has been calibrated and resampled to
a common pixel grid, we have multiple \emph{independent}
maximum-likelihood estimates of the source flux in our chosen filter,
each with a known standard deviation and Gaussian statistics.  That
is, we have multiple Gaussian likelihood functions that we wish to
combine.  Since they are independent, the combined likelihood is the
product of the individual likelihoods.  For Gaussian distributions,
the resulting aggregate maximum likelihood estimate is the
inverse-variance-weighted sum of the individual estimates.

If the calibration factor $\kappa_i$ scales image $i$ to flux in
common units, and $R_i$ represents resampling to the common pixel grid,
then the flux estimate $F_i$ is
\begin{eqnarray}
F_i &=& R_i(\kappa_i \, D_i)
\end{eqnarray}
with per-pixel error
\begin{eqnarray}
\sigma_{F, i} &=& \frac{\kappa_i \, \sigma_{1,i}}{\psfnorm_i}
\end{eqnarray}
and we combine the estimates from multiple images via
\begin{eqnarray}
F^{\star} &=& \frac{\displaystyle\sum_i F_i \, \sigma^{-2}_{F,i}}{\displaystyle\sum_i \sigma^{-2}_{F_i}}
\label{eq:onebandmap}
\end{eqnarray}
which has per-pixel error
\begin{eqnarray}
  \sigma_{F, \star} &=& \left( \sum_i \sigma^{-2}_{F,i} \right)^{-\frac{1}{2}}    \quad .
  \label{eq:onebandstd}
\end{eqnarray}
This is simply the maximum-likelihood estimate of the flux based on a
set of independent Gaussian estimates.


In summary, the procedure to produce an optimal detection map given
multiple images (in the same filter) is:
\begin{enumerate}
\item \emph{correlate} each image by its PSF model
\item \emph{calibrate} each resulting detection map (and its variance)
  to common units
\item \emph{resample} each calibrated detection map to a common pixel
  grid
\item \emph{coadd} the calibrated detection maps weighted by their
  inverse variances.
\end{enumerate}
Assuming well-sampled images, the \emph{correlation},
\emph{calibration}, and \emph{resampling} steps can occur in any
order.  Importantly, however, the \emph{coaddition} stage must occur
\emph{after} correlation by the point-spread functions of the
individual images; each image must be correlated by its own matched
filter to produce \emph{detection maps} which are then coadded.

\subsection{Comments}

\paragraph{Optimality}
In appendix \ref{app:multiopt} we show that the estimator $F^{\star}$
saturates the Cram\'er--Rao bound and is therefore statistically
optimal.

\paragraph{Coadds}
Occasionally, astronomers attempt to construct image coadds and then
detect sources by correlating the coadd with an estimate of its PSF.
It is straightforward to show that this is necessarily sub-optimal
unless the images have the same PSF.  Intuitively, the PSF of the
coadd is not equal to the PSF of either image, therefore this approach
uses a ``mismatched filter'' rather than a matched filter, resulting
in loss of signal-to-noise or detection efficiency.

\begin{figure}[h]
  \begin{center}
  \includegraphics[width=0.5\textwidth]{dont-coadd}
  \caption{Loss of signal-to-noise in computing a coadd and detecting
    sources in the coadd, rather than computing the detection map on
    the individual images.  Two images, with PSF widths differing by a
    factor of two, and exposure times such that the depths are
    similar, are coadded and sources detected.  Regardless of the
    weighting used to coadd the images, detection efficiency is lost
    compared to the method presented in this paper.\label{fig:dontcoadd}}
  \end{center}
\end{figure}

%
As an illustration, we simulated two images with similar detection
signal-to-noise but Gaussian PSFs that differed by a factor of two.
We computed the detection map, and also created a series of coadds
(trying different weights for the two images), computing the detection
map for each, using the correct coadded PSF.  As shown in Figure
\ref{fig:dontcoadd}, regardless of the coadd weight chosen, detecting
on the coadd results in a loss of efficiency compared to the detection
map.


\subsection{Different bandpass filters: the \emph{SED-matched filter}}

Everything we have said up to now has been based on facts about
statistical distributions and should be uncontroversial.  In this section we
propose a method that is, to our knowledge, new to astronomy.  While
it is fully defensible, it involves \emph{priors} so we expect will be
slightly controversial.  We argue that other proposed methods presume
\emph{stronger} and usually \emph{unstated} priors.

As we saw in the single-bandpass case, we can combine multiple
individual exposures into an aggregate estimate of the flux of a point
source.  In order to do this, it was essential to calibrate the images
so that each one was an estimate of the same underlying quantity.  The
multiple-bandpass case is similar: For each bandpass, we first combine
the images taken in that bandpass into an aggregate estimate.  Then,
to combine the bandpasses we must scale them so that they are
estimates of the same quantity.  This requires \emph{knowing} the
spectral energy distribution, or at least the \emph{colors} in the
filters of interest, of the source to be detected; this allows us to
scale the various bandpasses so that they are estimates of a common
quantity: perhaps the flux in a canonical band, or some other linear
quantity such as the integrated intensity.

%% FIXME -- does that make sense?  Apparent brightness?  Apparent
%% luminosity?  I just want to say, you could measure it in anything
%% linear, like W/m^2/sr/s or, heck, the projected area of a star of a
%% given temperature)


The intuition here is that if we know that our sources of interest are
twice as bright in bandpass A as in bandpass B, then we can convert an
estimate of the brightness in band B into an estimate of the
brightness in band A by multiplying by two.  The variance of the
scaled estimate increases appropriately (by a factor of four), so a
bandpass in which a source is expected to be faint will contribute an
estimate with a large variance and will be downweighted when the
estimates are combined.  We can also view the problem as one of
estimating a total flux that has been split into the different
bandpasses, and in that view the SED-matched filter is analogous to
the way flux is spread into pixels by the point-spread function (and
re-collected by correlating with the matched filter).

\newcommand{\sigdj}{\sigma_{j}}

Assume we have computed detection maps $D_j$, with per-pixel standard deviation
$\sigdj$, for a number of different bandpasses.  Assume each
bandpass has a known conversion factor $f_j$ to the canonical band;
that is,
\begin{eqnarray}
  D_j & \drawnfrom & \gaussx{f_j F}{\sigdj^2}
\end{eqnarray}
for flux in the canonical band $F$.
% \footnote{% The notation $x
%   \drawnfrom \gaussx{\mu}{\sigma^2}$ means that $x$ is drawn from a
%   Gaussian distribution with mean $\mu$ and variance $\sigma^2$.}
%
Given a number of such detection maps, we first scale them so they are all estimates of the
same quantity, by dividing by $f_j$:
\begin{eqnarray}
  F_j & = & \frac{D_j}{f_j} \\
  F_j & \drawnfrom & \gaussx{F}{\frac{\sigdj^2}{f_j^2}}
\end{eqnarray}
and assuming that the images  are independent, we combine them by inverse-variance weighting
to produce the maximum-likelihood estimate for $F$:
\begin{eqnarray}
  \hat{F} &=& 
  %\frac{\sum_j D_j \, f_j \, \sigdj^{-2}}%
  %     {\sum_j f_j^2 \, \sigdj^{-2}}
  \frac{\displaystyle\sum_j \frac{D_j}{f_j} \, \frac{f_j^2}{\sigdj^2}}%
       {\displaystyle\sum_j \frac{f_j^2}{\sigdj^2}}
       = 
       \frac{\displaystyle\sum_j D_j \, f_j \, \sigdj^{-2}}%
            {\displaystyle\sum_j f_j^2 \, \sigdj^{-2}}
\end{eqnarray}
with per-pixel error
\begin{eqnarray}
  \hat{\sigma}_F &=& \left( \sum_j f_j^2 \sigdj^{-2} \right)^{-\frac{1}{2}}
  \quad .
\end{eqnarray}


For example, if we treat $r$ band as the canonical band and our
objects of interest have color $r-i = 1$, then we 
expect the flux in $i$ to be a factor of $2.5$ greater than the
flux in $r$; $f_i = 2.5$, and we
will scale our
$i$-band detection map $D_i$ by $1/f_i = 0.4$.  Since the
sources are expected to be brighter in $i$ band, we must \emph{scale
  down} the $i$-band estimate to produce an $r$-band estimate.  The
$i$-band variance is also reduced in a corresponding way, so this does
not dilute the weight of high-precision measurements.


In practice, we advocate computing such maps for a set of spectral
energy distributions that sparsely sample the space of sources of
interest.  By performing multiple significance tests, more false
positives will be generated, but we argue that one can maintain the
same false positive rate by slightly increasing the detection
threshold.  Since we effectively extract more of the available
signal-to-noise by weighting the bands appropriately, our method
should still achieve superior completeness at a given purity.
%
More broadly, we argue that source detection should be used as in
\emph{initial} seed of the likely positions of sources, but that only
after \emph{inference} of the proposed source's properties using the
individual images should one decide whether the source should be kept.
This leads toward using slightly lower detection thresholds (that will
produce more false positives due to noise), plus additional
thresholding to determine which sources should be kept.


\subsection{Comments}

\paragraph{Chi-squared coadd.}
Szalay \etal \citep{szalay1999} present the idea of using the $\chi^2$
statistic of a set of images taken through different bandpass filters.
That is, they take pixel-aligned and possibly PSF-filtered images
(here we will use detection maps) and compute $\chi^2$ pixelwise,
\begin{eqnarray}
  \chi^2 &=& \sum_j \frac{D_j^2}{\sigma_{D_j}^2}
\end{eqnarray}
and a sufficiently large set of connected pixels with $\chi^2$ above a
detection threshold is taken as evidence as a source.  See Figure
\ref{fig:sedmatched}.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{sed-matched}
    \caption{SED-matched and ``chi-squared'' detection filters.  The
      data points are (chi-squared) peaks above $3 \sigma$ detected in
      $g$ and $r$ images taken with the Dark Energy Camera, plotted in
      signal-to-noise space.  Points that are below $10 \sigma$ in
      deeper data (25 exposures) are marked as ``False''; these are
      mostly clustered around zero (due to noise), with some scattered
      points near the axes due to artifacts such as cosmic rays. The
      main locus of ``Real'' peaks correspond to real stars and
      galaxies with typical colors.  The Chi-squared detection method
      selects as sources all sources outside the circle (including, in
      the naive formulation, sources with negative flux in both
      bands).  A single-band detection filter selects all sources
      above a vertical or horizontal detection threshold.  Our ``red''
      SED-matched filter selects sources where the fluxes in the two
      bands are consistent with a red SED (in this case, a $g - r$
      color of 1).  Note that the threshold line is roughly orthogonal
      to the line between the false positives and the true positives;
      it separates them efficiently.  We have shown the chi-squared
      detection filter with a threshold of $(5\sigma)^2$, which yields
      a higher false positive rate than a $5\sigma$ threshold in a
      single-band or SED-match filter.
      \label{fig:sedmatched}
    }
  \end{center}
\end{figure}

As \cite{szalay1999} state, the $\chi^2$ detection method represents
the probability that a pixel is drawn from the Gaussian sky background
distribution (independently in each band).  A large value is
considered to reject this null hypothesis.  The ``source'' hypothesis
is not stated, but implicitly, by choosing a constant $\chi^2$
threshold, a source is assumed to have any non-zero flux uniformly
distributed on the surface of the signal-to-noise (hyper-)sphere.  As
noted in the paper, this includes sources with negative fluxes in
every band.  While they suggest heuristics to trim such sources (for
example, demanding $> -1 \sigma$ of flux in each band), the fact that
these sources are detected in the first place hints at the primary
issue with this method: that the ``source'' hypothesis is not
physical.

Lacking a source model means that it is not always helpful to add more
data: Consider the case where we have one informative band and several
noisy (but still somewhat informative) bands.  The chi-squared method
treats all bands equally, thus mixes the one informative band with all
the uninformative bands.  When using multiple bands, the detection
threshold must be increased to maintain a constant false detection
rate (as detailed below), and therefore the number of true detected
sources will be lower.

As shown in Figure \ref{fig:sedmatched}, there is one additional
caveat for the chi-squared detection method: a $(5\sigma)^2$ threshold
yields a larger false positive rate than a standard single-band
detection filter with a threshold of $5\sigma$; in order to achieve a
desired false positive rate, the detection threshold must be set by
analysis (with two bands, the survival function of the chi
distribution at the equivalent of $5 \sigma$ is roughly 5.5; with
three bands it is roughly 5.75) or simulations (as suggested by
\cite{szalay1999}).

\cite{szalay1999} in fact also suggest a method for detecting objects
of a specific color that is similar but not identical to the approach
we present here; they suggest projecting the multiple bands into
subspaces and using their chi-squared approach in those subspaces,
which means that the issues identified above still hold.


\subsection{Going Bayesian}

The \emph{SED-matched filter} presented above tells us how to find
likely source positions given a source spectral energy distribution.
It is then natural (in a Bayesian framework) to \emph{marginalize}
over the SED using a prior distribution.  We can also marginalize over
the flux of the source, allowing us to compare the hypothesis that a
source exists, versus the hypothesis that the observed flux is due to
a noise fluctuation.

We can write the likelihood for a single pixel in the set of detection
maps $D_j$, given the existence of a source, as
\begin{equation}
  p_S(\{ D_j \}) = \iint p(\{ D_j \} | F, s) \, p(F) \, p(s) \, \dd F \, \dd s
\end{equation}
where $F$ is the flux of the source in some canonical band, and $s$ is
the SED of the source.  We will assume that the SED prior $p(s)$ is
represented as a weighted sum of discrete SEDs: a gridding of SED
space, for example.  We then have
\begin{eqnarray}
  p_S(\{ D_j \})
  &=&
  \sum_{i} w_i \int p(\{ D_j \} | F, s) \, p(F) \, \dd F
  \\
  &=&
  \sum_i w_i \int \prod_j \gaussian{D_j \,|\, F \cdot s_{i,j}, \sigma_j^2} \, p(F) \, \dd F
  \\
  &=&
  \sum_i w_i 
  \left( \prod_j \frac{1}{\sqrt{2 \pi} \sigma_j^2} \right)
  \int 
    \exp{ \left( \sum_j \frac{(D_j - F \cdot s_{i,j})^2}{-2 \, \sigma_j^2} \right) }
    \, p(F) \, \dd F
\end{eqnarray}
%
where we have written out the Gaussian likelihoods of the detection
maps, and the SEDs are represented as scalings of the canonical flux
$F$: for SED $i$, band $j$ is predicted to have flux $F \cdot
s_{i,j}$.

We must now specify a prior over the flux to make progress.  One
option that leads to a closed-form result is an exponential prior,
$p(F) = \alpha \exp(-\alpha F)$ and $F > 0$, with $\alpha$ a free
variable (to be chosen).  We caution that this prior does have some
undesirable properties, discussed below.  With this exponential flux
prior, we have
\begin{eqnarray}
  p_S(\{ D_j \})
  &=&
  K \alpha
  \sum_i w_i 
  %\left( \prod_j \frac{1}{\sqrt{2 \pi} \sigma_j^2} \right)
  %\exp{\left( \sum_j -\frac{d_j^2}{2 \sigma_j^2} \right)}
  %\, K %k \, \chi^2 \,
  \int 
    \exp{ \left( F \sum_j \frac{D_j s_{i,j}}{\sigma_j^2} \right)}
    \exp{ \left( -F \alpha \right)}
    \exp{ \left( F^2 \sum_j \frac{s_{i,j}^2}{\sigma_j^2} \right)}
    \, \dd F
\end{eqnarray}
%where we have introduced the constants
%\begin{eqnarray}
%k &=& \prod_j \frac{1}{\sqrt{2 \pi} \sigma_j^2}
%\\
%\chi^2 &=& \exp{\left( \sum_j -\frac{d_j^2}{2 \sigma_j^2} \right)}
%\end{eqnarray}
where we have pulled out the constant
\begin{eqnarray}
K &=& \prod_j \frac{1}{\sqrt{2 \pi} \sigma_j^2} 
\exp{\left( \sum_j -\frac{D_j^2}{2 \sigma_j^2} \right)}
%\\
%&=& \gaussian{D_j | 0, \sigma_j^2}
= \gaussian{D_j \,|\, 0, \sigma_j^2}
\label{eq:pbg}
\end{eqnarray}
which will be recognized as the zero-mean Gaussian probability of
$\{D_j\}$: the likelihood that data values $D_j$ are drawn from the
background distribution!

Defining variables
\begin{eqnarray}
  a_i &=& \alpha - \sum_j \frac{D_j s_{i,j}}{\sigma_j^2} \\
  b_i &=& \frac{1}{2} \sum_j \frac{s_{i,j}^2}{\sigma_j^2}
\end{eqnarray}
we get an integral in which the flux prior can be integrated analytically:
% eg
% http://www.wolframalpha.com/input/?i=integrate+e%5E-ax+e%5E-bx%5E2+dx+from+x%3D0+to+%2Binfinity
% integral_0^(+∞) e^(-a x) e^(-b x^2) dx =
% (sqrt(π) e^(a^2/(4 b)) erfc(a/(2 sqrt(b))))/(2 sqrt(b))
% IFF b>0 OR (b>=0 AND a>0)
% (phew, b>0 always)
%
\begin{eqnarray}
  p_S(\{ D_j \})
  &=&
  K \alpha
  \sum_i w_i 
  \int_0^{\infty}
    \exp(-a_i F) \exp(-b_i F^2)
    \, \dd F
    \\
  p_S(\{ D_j \})
  &=&
  K \alpha
  \sum_i w_i 
  \frac{\sqrt{\pi}}{2 \sqrt{b_i}}
  \exp \left(\frac{a_i^2}{4 b_i} \right)
  \left(1 - \erf\left( \frac{a_i}{2 \sqrt{b_i}} \right) \right)
  \label{eq:pfg}
\end{eqnarray}
which can be evaluated numerically with modest computational cost as
long as the number of SEDs $i$ is not too large.  In practice, a
coarse gridding of SED space yields good results, as shown below.

% and defining variables
% \begin{eqnarray}
%   \beta_i &=& 2 \sqrt{b_i} = \sqrt{2 \sum_j \frac{s_{i,j}^2}{\sigma_j^2}}
%   \\
%   %c_i &=& \frac{a_i}{2 \sqrt{b_i}}
%   c_i &=& \frac{a_i}{\beta_i}
% \end{eqnarray}
% we can write
% \begin{eqnarray}
%   p_S(\{ d_j \})
%   &=&
%   K \alpha
%   \sum_i w_i 
%   \frac{\sqrt{\pi}}{\beta_i}
%   \exp(c_i^2) \left[ 1 - \erf(c_i) \right]
% \end{eqnarray}


In order to select sources, we can compare this likelihood to the
null-hypothesis likelihood: that there is no source and the observed
values are due to noise.  Conveniently, the null-hypothesis likelihood
is exactly the factor $K$ in the above expression.  Determining the
threshold at which to accept a peak in the $p_S/K$ map as a source can
be framed as a Bayesian decision theory problem, or can be tuned on
simulations to yield an acceptable false positive rate.

%% FIXME -- can we do it analytically?

\begin{figure}
    \begin{center}
    \includegraphics[width=0.4\textwidth]{prob-contours-a}
    \includegraphics[width=0.4\textwidth]{prob-rel-a}
    \caption{ \emph{Left:} likelihood contours for the background
      model (there is no source, only noise), and the foreground
      model, where the SED prior is a single ``red'' SED with color $g
      - r = 1$.  Note that the contours are inclined in the direction
      of the SED (shown by a faint line).  The contours are at powers
      of 10.  \emph{Right:} likelihood ratio contours for the
      foreground divided by background model.  The contours are at
      powers of 10.
      \label{fig:cona}
    }
    \end{center}
\end{figure}

\begin{figure}
    \begin{center}
    \includegraphics[width=0.4\textwidth]{prob-contours-b}
    \includegraphics[width=0.4\textwidth]{prob-rel-b}
    \caption{ \emph{Left:} likelihood contours for the background
      model (there is no source, only noise), and the foreground
      model, where the SED prior is a weight sum of three SEDs: 49\%
      ``red'' (color $g-r=1$ mag), 49\% ``flat'' (color $g-r=0$), and
      2\% $r$-band only ($g$ flux is zero).  Note that the contours
      have components inclined in the directions of the SED components
      (shown by faint lines).  The contours are at powers of 10.
      \emph{Right:} likelihood ratio contours for the foreground
      divided by background model.  The contours are at powers of 10.
      \label{fig:conb}
    }
    \end{center}
\end{figure}

To illustrate the method, we consider a case where we have two bands
of imaging, $g$ and $r$ bands.  In \figref{fig:cona}, we plot the
probability contours of the background model (equation \ref{eq:pbg})
and the foreground model (equation \ref{eq:pfg}), for the simplest
case where our SED prior $p(s)$ is a delta function at $s_{g} =
\frac{1}{3.5}$, $s_{r} = \frac{2.5}{3.5}$: this is a ``red'' detection
filter that assumes a $g - r$ color of 1 magnitude.  As expected, the
probability contours of the foreground model shift away from negative
fluxes and toward fluxes that are consistent with the expected color.
The exponential prior on flux causes the foreground model to prefer
sources with small fluxes, and therefore the probability mass of the
foreground model is clustered around zero.  The probability ratio
contours---which are what would be used to accept or reject a proposed
source---are, as expected, orthogonal to the expected SED vector.

In \figref{fig:conb}, we show probability contours for a three-SED
model, including the ``red'' SED and a ``flat'' SED ($r$ flux equals
$g$ flux) with equal weights of $0.49$, plus an SED that has only flux
in the $r$ band, with weight $0.02$.  The probability contours of this
model are, as before, extended in the directions of these SEDs.  The
probability ratio contours transition smoothly between being
orthogonal to these three SED directions.


\begin{figure}
    \begin{center}
    \includegraphics[width=0.4\textwidth]{prob-contours-c}
    \includegraphics[width=0.4\textwidth]{prob-1d}
    \caption{ \emph{Left:} Likelihood contours for the ``red''
      foreground model, as before, and with the SED scaled by a factor
      of two.  When the SED factors are scaled up, the underlying flux
      prior is stretched out---larger observed fluxes are considered
      more probable.  \emph{Right:} A one-dimensional example showing
      the effect of scaling the SED by a factor of two.  The scaled
      model (dashed) places more prior belief in larger fluxes, and
      therefore must produce smaller probabilites at low flux levels.
      This illustrates that care must be taken with the units of $F$
      when using this prior.
      \label{fig:scaling}
    }
    \end{center}
\end{figure}


As mentioned previously, there is an issue with the flux prior we are
using: it is not scale-free, or rather, it is degenerate with the
choice of $\alpha$.  That is, the posterior probability is sensitive
to the numerical values for the quantity $F$, the ``canonical flux'',
which we have marginalized out of the expression.  We did not put any
restrictions on the SED values $s_{i,j}$; we only stated that the
predicted flux in band $j$ is given by $F \cdot s_{i,j}$.  If we were
to scale up all our $s_{i,j}$ values, this would imply a decrease in
$F$, which would have higher prior probability, leading to larger
posterior probability values.  This problem is illustrated in
\figref{fig:scaling}.  This is obviously undesirable, but thus far we
have not been able to find a scale-free prior that leads to tractable
integrals.





\section{Experiments}

We present experiments using data from the Dark Energy Camera
\citep{decam} taken as part of the Supernova program \citep{dessn} of
the Dark Energy Survey \citep{des}.  We selected the deep field ``SN
X3'' near RA,Dec $= (36.45, -4.6)$, which has a large number of
exposures in bands $g$, $r$, $i$ and $z$.  For these experiments, we
use data from bands $g$, $r$ and $i$ only.  We select a set of 25
exposures in each band from the 2016B semester, keeping at most one
exposure per night per band.  The exposure times for each image are
200 seconds in $g$, 400 seconds in $r$, and 360 seconds in $i$.  The
images have a range of seeing and sky transparency values.  The list
of exposures is available in Table \ref{tab:exposures}.

We use the standard NOAO DECam Community Pipeline \citep{cppipeline}
for calibration of the images, and then compute astrometric and
photometric zeropoints, sky background models and PSF models, using
the DESI Legacy Surveys pipeline \citep{lsoverview}.  The astrometric
calibration uses Gaia (DR1) as the reference catalog \citep{gaia, gaiaDR1}, and
the photometric calibration uses the Pan-STARRS DR1 reference catalog
\citep{panstarrs}.


\subsection{Sloan Digital Sky Survey}

Here we present some proof-of-concept experiments on Sloan Digital Sky
Survey (SDSS) data from the Stripe 82 region \cite{sdss}.

% FIXME -- The results show XYZ...

\paragraph{Input data selection.}
We select input exposures to include as follows.  Using the
``window\_flist'' table for SDSS Data Release 9 \cite{dr9}, we select
photometric exposures from camera column 3, with RA in the range
$[45.15, 45.85]$ and Dec in the range $[-0.2, -0.1]$.  This results in
$109$ fields from $23$ unique runs, which are listed in
\tabref{tab:fields}.

\paragraph{\Detmap\ and resampling.}
For each input image, we take the PSF to be the double-Gaussian model
computed by the SDSS \emph{Photo} pipeline \cite{photo}, and compute
the \detmap.  Since SDSS DR9 images are already in sky-subtracted,
calibrated ``nano-maggies'', we do not need to apply a calibration
factor to convert them to common units, nor do we need to remove a sky
background level.  We set to zero any image pixels that are masked as
saturated, interpolated, cosmic ray, ghost, or ``not checked'' (close
to the image boundaries).
% 'INTERP', 'SATUR', 'NOTCHECKED', 'GHOST', 'CR'
We compute the per-pixel noise ($\sigma_1$) based on a Gaussian
approximation of the Poisson errors from the mean sky level, plus dark
current and read noise, as recommended by the SDSS
team.\footnote{\niceurl{http://data.sdss3.org/datamodel/files/BOSS\_PHOTOOBJ/frames/RERUN/RUN/CAMCOL/frame.html}}


For each of the $u$, $g$, $r$, $i$ and $z$ bandpass filters
(``bands''), we resample to a common pixel grid and then compute a
per-band \detmap\ as per \eqnref{eq:onebandmap}.  The common pixel
grid is defined by a WCS tangent-plane projection centered on our
patch of interest with the nominal SDSS pixel scale (0.396 arcseconds
per pixel) and image size $4096 \times 2048$ \cite{wcs}.  Since the
SDSS pipeline adds a 128-pixel overlap between neighboring fields in a
run, we first build a \detmap\ for each run, averaging values in the
overlapping regions to avoid double-counting, then combine these
per-run \detmap s as per \eqnref{eq:onebandmap}.  For resampling we
use a third-order Lanczos kernel.

% We track the inverse-variance on a per-pixel basis

\paragraph{Background correction.}
We find that there is considerable spatially-coherent structure in our
combined \detmap s, which we suspect is due to slightly biased
background subtraction in the SDSS pipeline code.  We estimate and
remove a residual background as follows.  After masking all pixels
above 5 sigma, we compute the median value within each cell of a $\sim
100 \times 100$-pixel grid, and interpolate between these values with
a third-order B-spline.  The resulting background-subtracted \detmap s
have no apparent background structure (by eye) and their pixel
distributions are closer to Gaussian.  See \figref{fig:bg}.

\paragraph{Detection}
In this \doctype\ we are not concerning ourselves with blended
objects, so we identify peaks in the \detmap\ naively.  We find
pixels above the desired threshold, expand by a 2-pixel radius, and
find the connected components.  For each component, we return the peak
pixel, ignoring other peaks within the component.


We construct a series of spectral energy distributions (SEDs),
building the combined \detmap\ and running the peak detection
algorithm for each.  A standard approach for detecting objects in
imaging from multiple bands is to weight each band by its
signal-to-noise.  This is equivalent to assuming a flat spectrum, or
zero color.  Our SED-matched filters weight each band according to
both the amount of flux we expect to see in the band, and its
signal-to-noise.  The SEDs we use here include ``Flat'' (expected
color $g = r = i$), ``Red'' ($g-r = r-i = 1$), ``Blue'' ($g-r = r-i =
-1$), and four points lying approximately along the stellar locus
($(g-r, r-i)$ colors $(0.5,0.2)$, $(1.0,0.4)$, $(1.4,0.7)$, and
$(1.4,1.4)$.  In the experiments here we will compare the detection
strengths in the different SEDs.  In practice we would return the
union of peaks detected in this way.



% XXX: Verify this statement
% XXX: Cite ``standard approach''
% XXX: Advice on what to do in practice?

\paragraph{Results}
In \figref{fig:redblue} we show that objects with red colors in the
SDSS catalog are detected more strongly by our SED-matched Red filter
than a Flat SED (which corresponds to the traditional multi-band
detection approach).  There are very few objects that the Blue
SED-matched filter detects more strongly than the Flat or Red filters;
astrophysical objects with blue colors (bluer than 0 in the AB system)
are rare.

% (in the AB system of SDSS)

In \figref{fig:colorcolor} we show, in color-color space, the sources
detected by each of our SED-matched filters.  As expected, each filter
is most sensitive to sources in a given region of color-color space.

% FIXME -- show strongest detections for each SED.

In \figref{fig:missed} we show postage-stamp images of sources that
are detected by our SED-matched filters and not detected by a
traditional approach.  In \figref{fig:added} we show in color-color
space the additional objects that are detected as we apply a sequence
of SED-matched filters.



\subsection{Simulations}

---Single exposure, single band

---Multiple exposures (different PSFs, sky), single band

---Multiple exposures, multiple bands









\begin{table}
\begin{center}
\begin{tabular}{|r|r|r|}
\hline
Run & Min field & Max field \\
\hline
1752 & 163 & 166 \\
1887 & 107 & 111 \\
2578 & 112 & 116 \\
2589 & 200 & 204 \\
2700 & 168 & 171 \\
2738 & 220 & 224 \\
2820 & 168 & 172 \\
2861 & 86 & 90 \\
2873 & 211 & 215 \\
3362 & 169 & 173 \\
3384 & 671 & 675 \\
3461 & 20 & 24 \\
4128 & 425 & 429 \\
4157 & 178 & 181 \\
4198 & 664 & 668 \\
4207 & 673 & 677 \\
4849 & 757 & 760 \\
4858 & 656 & 660 \\
4874 & 723 & 727 \\
4905 & 304 & 307 \\
4927 & 654 & 658 \\
4933 & 665 & 668 \\
4948 & 245 & 249 \\
\hline
\end{tabular}
\caption{SDSS fields included in the experiments.  All fields are from
  camera column (``camcol'') 3.  The minimum and maximum (inclusive)
  fields are listed.\label{tab:fields}}
\end{center}
\end{table}



\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{detect-r-00} \\
\includegraphics[width=0.7\textwidth]{detect-r-01} \\
\includegraphics[width=0.8\textwidth]{detect-r-02}
\caption{Residual background subtraction.  \textbf{Top:} combined
  \detmap\ for the SDSS $r$ band, combining images from 23 runs.
  There are clear patterns in the background level.  \textbf{Middle:}
  after estimating and removing the residual background as described
  in the text, the background appears more flat.  \textbf{Bottom:}
  after removing the background, the pixel error statistics are closer
  to Gaussian, though the distribution is still significantly
  broader than expected.\label{fig:bg}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-11}
\caption{Detection strengths in the Red, Flat, and Blue SED-matched
  filters, versus SDSS-measured colors.  We performed a spatial match
  between our detected sources and SDSS sources (from the DR7 CasJobs
  database ``Stripe82''; \cite{annis}) within 1 pixel.  Redder objects
  in $g-i$ are detected more strongly in the Red SED-matched filter
  than Flat or Blue.  The handful of objects with significantly blue
  colors are detected more strongly with the Blue filter.
  \label{fig:redblue}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-17}
\caption{Color-color space locations of sources detected most strongly
  by each of the filters.
  The color measurements are from the SDSS
  Stripe82 coadd catalog \cite{annis}, matched to
  our detections using a 1-pixel matching radius.
  It is clear that
  our different SED-matched filters are tuned to detect objects in
  particular regions of color-color space.  The ``X'' marks indicate
  the color each SED-matched filter is tuned for.  Note that many of
  the sources are detected above a given detection threshold by
  several of the SED-matched filters; here each source is assigned to
  the filter by which it is detected most strongly.
  \label{fig:colorcolor}}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-14}
\includegraphics[width=0.8\textwidth]{mdetect-15}
\includegraphics[width=0.8\textwidth]{mdetect-16}
\caption{Sources detected by our SED-matched filters and not by a
  ``traditional'' approach; full caption on next page\label{fig:missed}}
\end{center}
\end{figure}

\addtocounter{figure}{-1}
\begin{figure}
\begin{center}
\caption{[figure previous page] Sources detected by applying a
  sequence of SED-matched filters.  We start with sources detected by
  a ``traditional'' approach that takes the union of single-band
  detections in each of the $g$, $r$, and $i$ filters.  We then apply,
  in sequence, our Flat, Red, and Stellar locus SED-matched filters.
  Each panel shows the sources detected by the new filter and not
  detected by previous filters, in order of decreasing
  signal-to-noise.  In order to make the objects easier to see, we
  have increased the detection threshold to $20 \sigma$.}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{mdetect-18}
\caption{Color-color space locations of additional sources detected as
  additional SED-matched filters are applied.  We start by taking all
  single-band detections in the $g$, $r$, and $i$-band filters.  Next,
  we add sources detected by the Flat SED-matched filter, then the Red
  filter, then a set of filters along the stellar locus.  Each
  subsequent SED-matched filter detects sources that are missed (at a
  fixed detection threshold) by the previous filters.
  %The color measurements are from the SDSS
  %Stripe82 coadd catalog \cite{annis}, matched to
  %our detections using a 1-pixel matching radius.
  \label{fig:added}}
\end{center}
\end{figure}


\section{Discussion}

--similarities and differences from Szalay et al 1999 -- SED-matched
filters $\sim$ ``optimal subspace filtering''

--galaxy detection?

--No weights go to zero -- all images contribute *something*, in
proportion to t he information they bring.  Contrast with lucky
imaging and some co-adding schemes.

--sub-pixel shifts: lower threshold so that max pixel is above
threshold; post-process to cut out peaks that really were below
threshold.


\section{Conclusions}

[[What to do with a detection image; how to proceed.  Build models,
    fit simultaneously to all images in the ``stack''.]]

[[Practicalities: bad pixels / masks, interpolation, etc]]

\acknowledgements

Ben Weiner (University of Arizona),
Julianne Dalcanton (University of Washington),
Brad Holden (UCO/Lick Observatories),
Micha Gorelick (Fast Forward Labs),
Robert Lupton, Steve Bickerton, Paul Price, and Craig Loomis (Princeton)


%\bibliographystyle{plain}
\bibliographystyle{apj}
\bibliography{detection}



\appendix

\section{Appendices}

\subsection{Optimal linear detection}
\label{app:lindet}

Let us assume that there exists a linear filter whose output allows
optimal detection of isolated point sources.  That is, we seek a
(two-dimensional) set of coefficients $a_{\ivec}$ that, when
correlated with the image $I_{\jvec}$, produces a map $M_{\jvec}$
whose peak is the likely location of the point source.  See
\figref{fig:detmap}.


The linear filtering (correlation) operation is
\begin{equation}
M_{\jvec} = \sum_{\iina} a_{\ivec} \, I_{\ivec + \jvec}
\label{eq:detmap1}
\end{equation}
where $\mathcal{A}$ is the support of $\avec$ (integer pixel
positions), and the center of $\avec$ is $\coord{0}{0}$.  We will
demand that the elements of $\avec$ are non-negative and sum to unity.

Inserting \eqnref{eq:modelimg}, we get
\begin{eqnarray}
M_{\jvec} &\drawnfrom& \sum_{\iina}
  I_k \, a_{\ivec} \, \psfat{\ivec + \jvec - \kvec} + \gaussx{0}{\sigma_1^2}
  \\
&\drawnfrom& \gaussx{ I_k \sum_{\iina} a_{\ivec} \, \psfat{\ivec + \jvec - \kvec}}%
    {\sum_{\iina} a_{\ivec}^2 \, \sigma_1^2}
\end{eqnarray}
and the per-pixel signal-to-noise in the map is
\begin{equation}
%  \signoise_{D_{\jvec}} = \frac{I_k \, \sum_{\iina} a_{\ivec} \, \psfat(\ivec + \jvec - \kvec)}{\sigma_1 \sqrt{\sum_{\iina} a_{\ivec}^2}}
  \snr{M_{\jvec}} = \frac{I_k \, \sum a_{\ivec} \, \psfat{\ivec + \jvec - \kvec}}{\sigma_1 \sqrt{\sum_{\ivec} a_{\ivec}^2}} \quad .
  \label{eq:detmapsn1}
\end{equation}

We want to choose coefficients $a_{\ivec}$ to maximize the 
signal-to-noise at the true pixel position of the source,
$\kvec$.  Rewriting the expression using dot-products and
norms\footnote{All norms in this \doctype\ are $\ell_2$ norms: $\norm{X} =
  \sqrt{\sum_i X_i^2}$.}, treating the two-dimensional images
$a_{\ivec}$ and $\psfat{\ivec + \jvec - \kvec}$ as vectors indexed by
$\ivec$, we have:
\begin{eqnarray}
  %\signoise_{D_{\jvec}} &=& \frac{I_k \, \avec \cdot \bm{\psfat(\jvec-\kvec)}}{\sigma_1 \sqrt{\avec \cdot \avec}} \\
  \snr{M_{\jvec}} &=& \frac{I_k \, \avec \cdot \bm{\psfat{j-k}}}{\sigma_1 \sqrt{\avec \cdot \avec}} \label{eqn:psfdotprod} \\
 &=& \frac{I_k \, \norm{\avec} \norm{\bm{\psfat{j-k}}} \cos \theta}{\sigma_1 \norm{\avec}} \\
 &=& \frac{I_k \, \norm{\bm{\psfat{j-k}}} \cos \theta}{\sigma_1}
\end{eqnarray}
where $\theta$ is a generalized angle between $\avec$ and $\bm{\psfat{j-k}}$.
At the pixel position of the source, $\kvec$,
\begin{equation}
\snr{M_{\kvec}} = \frac{I_k \, \norm{\bm{\psfat{0}}} \cos \theta}{\sigma_1}
\label{eqn:sndsingle}
\end{equation}
Clearly this is maximized when $\theta = 0$, \ie, when $\avec$ is a
multiple of $\bm{\psfat{0}}$, the PSF evaluated at a grid of integer
pixel positions.  Since we have defined both the PSF and coefficients
$a$ to sum to unity, we find that the optimal linear filter for
detection is given by:
\begin{equation}
%  a_{\ivec} = \psfat{\ivec} \quad ,
\avec = \bm{\psfat{0}} \quad ,
\end{equation}
which means that the operation of \emph{correlating} the image with
its PSF produces a map with optimal signal-to-noise.  Repeating
equation \ref{eq:detmap1}, we have found that the map $M_{\jvec}$ can
be computed by correlating the image with its PSF:
\begin{equation}
M_{\jvec} = \sum_{\iina} \psfat{\ivec} \, I_{\ivec + \jvec} \quad ,
\end{equation}
where, as before, $\mathcal{A}$ is the support of the PSF.
% and
%$\psfat{\ivec} = \psfat{\ivec}$ is an image of the PSF evaluated at
%integer pixel positions $\ivec$.

The signal-to-noise in this map at the true source pixel
position $\kvec$ is
\begin{equation}
\snr{M_{\kvec}} = \frac{I_k \, \norm{\bm{\psfat{}}}}{\sigma_1} \quad .
\end{equation}


\subsubsection{Optimality}
\label{sec:optsingle}

We compute the variance of the detection map estimator
(\eqnref{eq:detmap}), and show that is equal to the Cram\'er--Rao
bound.  Substituting our image model into the detection map,
\begin{eqnarray}
D_{\jvec} &=& \frac{1}{\psfnorm^2} \sum_{i} \psfat{\ivec} \,
I_{\ivec + \jvec}
\\
& \drawnfrom & \frac{1}{\psfnorm^2} \sum_{i} \psfat{\ivec} \,
\gaussx{F \, \psfat{\ivec + \jvec - \kvec}}{\sigma_1^2}
\end{eqnarray}
and at the true source position, $\jvec = \kvec$;
\begin{eqnarray}
%D_{\jvec} &\drawnfrom& 
%\frac{1}{\psfnorm^2} \sum_{i}
%\gaussx{F \, \psfat{\ivec}^2}{\psfat{\ivec}^2 \sigma_1^2}
%
D_{\kvec} &\drawnfrom& \frac{1}{\psfnorm^2} \gaussx%
{F \, \sum_{i} \psfat{\ivec}^2}%
{\sum_{i} \psfat{\ivec}^2 \sigma_1^2}
\\
D_{\kvec} &\drawnfrom& \gaussx%
{F}{\frac{\sigma_1^2}{\psfnorm^2}}
\end{eqnarray}
so the variance of the estimator is $\var{D} = \frac{\sigma_1^2}{\psfnorm^2}$.

Meanwhile, the Fisher Information for $F$ given pixel values $I_{\jvec}$ is
\begin{eqnarray}
  I(F) &=& -\mathbb{E}_{I_{\jvec}} \left[ \frac{\partial^2 \log P(\{ I_{\jvec} \} | F)}{\partial F^2} \right]
\end{eqnarray}
and with pixel values $I_{\jvec}$ the likelihood is
\begin{eqnarray}
  I_{\jvec} &\drawnfrom& \gaussx{F \psf_{\jvec}}{\sigma_1^2} \\
  P(\{ I_{\jvec} \} | F) &=& \prod_{\jvec} \frac{1}{\sqrt{2 \pi \sigma_1^2}} \exp \left( -\frac{(I_{\jvec} - F \psf_{\jvec})^2}{2 \sigma_1^2} \right) \\
  %\log P(\{ I_{\jvec} \} | F) &=& \sum_{\jvec} \log \frac{1}{\sqrt{2 \pi \sigma_1^2}} + \sum_{\jvec} -\frac{(I_{\jvec} - F \psf_{\jvec})^2}{2 \sigma_1^2} \\
  %\frac{\partial}{\partial F} \log P(\{ I_{\jvec} \} | F) &=& \sum_{\jvec} \frac{(I_{\jvec} - F \psf_{\jvec}) \psf_{\jvec}}{\sigma_1^2} \\
  \frac{\partial^2}{\partial F^2} \log P(\{ I_{\jvec} \} | F) &=& \sum_{\jvec} -\frac{\psf_{\jvec}^2}{\sigma_1^2}
\end{eqnarray}
which is independent of $I_{\jvec}$, so
\begin{eqnarray}
  I(F) &=& \frac{\norm{\psf}^2}{\sigma_1^2}
\end{eqnarray}
from which we see that the estimator $D$ saturates the Cram\'er--Rao bound.

\subsubsection{Norm of a Gaussian PSF}
\label{app:gaussnorm}
For a Gaussian PSF with standard deviation $\psfw$ pixels,
\begin{eqnarray}\displaystyle
\psf^G(x,y) &=& \frac{1}{2 \pi \psfw^2} \exp{\left(-\frac{x^2}{2 \psfw^2}\right)} \exp{\left(-\frac{y^2}{2 \psfw^2}\right)}
\end{eqnarray}
the norm is% approximately:
\begin{eqnarray}
\norm{\bm{\psf^G}} &=& \sqrt{ \sum_{x} \sum_{y} \left(\frac{1}{2 \pi \psfw^2} \exp{\left(-\frac{x^2}{2 \psfw^2}\right)} \exp{\left(-\frac{y^2}{2 \psfw^2}\right)} \right)^2} \\
%\left(\norm{\psf^G}\right)^2 &\simeq& \iint \frac{1}{4 \pi^2 \psfw^4} \exp{\left(-\frac{x^2}{\psfw^2}\right)} \exp{\left(-\frac{y^2}{\psfw^2}\right)} \mathrm{d}x \, \mathrm{d}y \\
\norm{\bm{\psf^G}} &\simeq& \sqrt{\iint \frac{1}{4 \pi^2 \psfw^4} \exp{\left(-\frac{x^2}{\psfw^2}\right)} \exp{\left(-\frac{y^2}{\psfw^2}\right)} \mathrm{d}x \, \mathrm{d}y} \\
\norm{\bm{\psf^G}} &\simeq& \frac{1}{2 \sqrt{\pi} \psfw}
\end{eqnarray}
so the \detmap\ has signal-to-noise at the true source position $\kvec$,
\begin{equation}
\snr{D_{\kvec}^G} = \frac{I_k}{2 \sqrt{\pi} \psfw \sigma_1 } \quad .
\label{eqn:sndsinglegauss}
\end{equation}

Note, however, that we have defined the point-spread function
$\psfat(\cdot)$ to be the \emph{pixel-convolved} response, so it cannot
be exactly Gaussian if the pixel response is assumed to be a boxcar
function.  In practice, however, a two-dimensional Gaussian with
variance $v^2$ correlated with a two-dimensional boxcar function is
well approximated by a Gaussian with variance $v^2 + \frac{1}{12}$, as
long as $v \gtrsim \frac{1}{2}$.

% figure showing this?




\subsubsection{Why not signal-to-noise-squared?}
In correlating the image with the PSF, it looks like the
\detmap\ weights pixels by their signal-to-noise, rather than
signal-to-noise \emph{squared}.  This apparent conflict can be
resolved by scaling the pixel values so that each pixel is an estimate
of the same quantity.  That is, we want to estimate the total source
counts $F$, but the pixels contain estimates of the source counts
scaled by the PSF, $F \psf$; we must undo this scaling by multiplying
the pixels by $1/\psf$.

Given a source at position $\kvec$, we define the image $K$ whose
pixels each contain an estimate of the total source counts:
\begin{eqnarray}
  K_{\jvec} &=& \frac{1}{\psfat{\jvec-\kvec}} S_{\jvec}  \\
  K_{\jvec} &\drawnfrom& \frac{1}{\psfat{\jvec-\kvec}} \, \gaussian{I_k \, \psfat{\jvec-\kvec}\, , \, \sigma_1^2} \\
  K_{\jvec} &\drawnfrom& \gaussian{I_k \, , \, \frac{\sigma_1^2}{\psfat{\jvec-\kvec}^2}} \quad .
\end{eqnarray}

The signal-to-noise remains the same, since we have just scaled the
values:
\begin{eqnarray}
\snr{K_{\jvec}} &=& \frac{I_k \, \psfat{\jvec-\kvec}}{\sigma_1} \\
\snr{K_{\jvec}} &=& \snr{S_{\jvec}} \quad .
\end{eqnarray}


As before, the \detmap\ pixels are a linear combination of the
(shifted) pixels of the $K$ image with weights $b_{\ivec}$:
\begin{eqnarray}
D_{\jvec}^\star &=& \sum_{\ivec} b_{\ivec} \, K_{\ivec+\jvec} \\
&\drawnfrom& \sum_{\ivec} b_{\ivec} \, \gaussian{I_k \,,\, \frac{\sigma_1^2}{\psfat{\ivec+\jvec-\kvec}^2}} \\
&\drawnfrom& \gaussian{I_k \sum_{\ivec} b_{\ivec} \,,\, \sum_{\ivec} \frac{b_{\ivec}^2 \sigma_1^2}{\psfat{\ivec+\jvec-\kvec}^2}}
\end{eqnarray}
and the signal-to-noise in that \detmap\ at pixel $\kvec$ is
\begin{eqnarray}
\snr{D_{\kvec}^\star} &=& \frac{I_k \sum_{\ivec} b_{\ivec}}{\sigma_1 \sqrt{\sum_{\ivec} \frac{b_{\ivec}^2}{\psfat{\ivec}^2}}}
\end{eqnarray}
which is maximized by setting the $b_{\ivec}$
\begin{equation}
b_{\ivec} \propto \psfat{\ivec}^2 \quad :
\end{equation}
proportional to the signal-to-noise \emph{squared}, as expected.

% Derivative is
% d\snr{D_k^\star}/db_k = 
%  \[ \frac{f}{\sigma} [ \frac{1}{\sqrt{\sum_j \frac{b_j^2}{\psfat{j}^2}}}
%                       - \frac{(\sum_j b_j) b_k}{\psfat{j}^2 (\sum_j \frac{b_j^2}{\psfat{j}^2})^{3/2}} ]
% \]
%
% And through some seemingly circular math you get to:
% b_k = \psfat{k}^2 * ( \sum_j (b_j^2 / \psfat(j)^2) ) / (sum_j (b_j))
%
% (you can remove the b_k term from the sums over j if you want, with no effect.)
%
% So b_k = \alpha \psfat{k}^2; substituting that you get:
%
% b_k = \psfat{k}^2 * ( \sum_j ( (\psfat{j}^2 \alpha)^2 / \psfat{j}^2 ) / (sum_j (\psfat{j}^2 \alpha))
%     = \psfat{k}^2 * ( \alpha^2 \sum_j \psfat{j}^2 ) / (\alpha \sum_j(\psfat{j}^2))
%     = \psfat{k}^2 * \alpha



\subsection{Multi-image detection}
\label{app:multidet}

\subsubsection{Optimality}
\label{app:multiopt}
As before, we will show that the estimator $F^{\star}$ in
Equation \ref{eq:onebandmap} saturates the Cram\'er--Rao bound for $F$.

We will consider two images, $A$ and $B$, with PSFs $\psi$ and $\phi$,
respectively, and calibration factors $\kappa_A$ and $\kappa_B$ that
scale image units to flux units.  Per-pixel noise in the two images
will be $\sigma_A$ and $\sigma_B$.  We will assume that the pixel
grids are aligned so that no resampling is necessary.

Given all this, the pixel value for images $A$ and $B$ are drawn from
the distributions
\begin{eqnarray}
  A & \drawnfrom & \gaussx{\frac{F}{\kappa_A} \psi_k}{\sigma_A^2} \\
  B & \drawnfrom & \gaussx{\frac{F}{\kappa_B} \phi_k}{\sigma_B^2}
  \quad .
\end{eqnarray}
The Fisher Information is
\begin{eqnarray}
  I(F) &=& -\mathbb{E}_{A,B} \left[ \frac{\partial^2 \log P(\{ A,B \} | F)}{\partial F^2} \right]
\end{eqnarray}
and assuming that images $A$ and $B$ are statistically independent,
$P(A,B | F) = P(A|F) P(B|F)$.  Following the analysis in
\ref{sec:optsingle}, we find that
\begin{eqnarray}
  I(F) &=& \frac{\norm{\psi}^2}{\kappa_A^2 \sigma_A^2} +
  \frac{\norm{\phi}^2}{\kappa_B^2 \sigma_B^2}
\end{eqnarray}
which equals the variance of the $F^{\star}$ estimator,
$\sigma_{F^{\star}}^2$ as given in Equation \ref{eq:onebandstd}.
Therefore, the estimator saturates the Cram\'er--Rao bound.


\subsection{Experiments}

\begin{table}
  \begin{center}
    \begin{tabular}{cccccc}
      Filter & Exposure number & Date & Exposure time (s) &
      Seeing (arcsec) & Depth ($5 \sigma$ point source) \\
      g & 563982 & 2016-08-14 & 200 & 1.28 & 24.65 \\
      g & 566968 & 2016-08-24 & 200 & 1.79 & 23.02 \\
      g & 567422 & 2016-08-25 & 200 & 1.72 & 23.55 \\
      g & 569591 & 2016-08-31 & 200 & 1.55 & 24.39 \\
      g & 571049 & 2016-09-05 & 200 & 1.67 & 24.29 \\
      g & 573546 & 2016-09-11 & 200 & 1.42 & 24.49 \\
      g & 574702 & 2016-09-14 & 200 & 2.17 & 22.75 \\
      g & 575794 & 2016-09-22 & 200 & 1.20 & 24.17 \\
      g & 577432 & 2016-09-26 & 200 & 1.55 & 24.47 \\
      g & 579874 & 2016-10-02 & 200 & 1.37 & 24.51 \\
      g & 582140 & 2016-10-09 & 200 & 1.61 & 23.56 \\
      g & 584106 & 2016-10-20 & 200 & 1.64 & 24.05 \\
      g & 585888 & 2016-10-25 & 200 & 2.00 & 24.11 \\
      g & 588620 & 2016-11-02 & 200 & 1.39 & 24.43 \\
      g & 591449 & 2016-11-09 & 200 & 1.47 & 23.53 \\
      g & 593383 & 2016-11-17 & 200 & 1.53 & 24.39 \\
      g & 595093 & 2016-11-22 & 200 & 1.45 & 24.48 \\
      g & 596474 & 2016-11-26 & 200 & 1.07 & 24.80 \\
      g & 598232 & 2016-12-01 & 200 & 1.96 & 23.91 \\
      g & 600846 & 2016-12-08 & 200 & 1.20 & 23.69 \\
      g & 601468 & 2016-12-17 & 200 & 1.32 & 23.41 \\
      g & 603288 & 2016-12-22 & 200 & 1.55 & 24.35 \\
      g & 604684 & 2016-12-28 & 200 & 1.82 & 24.26 \\
      g & 605946 & 2017-01-03 & 200 & 1.75 & 24.11 \\
      g & 609567 & 2017-01-17 & 200 & 1.17 & 24.14 \\
      \hline \\
      r & 563978 & 2016-08-14 & 400 & 1.37 & 24.51 \\
      r & 566976 & 2016-08-24 & 400 & 1.58 & 23.57 \\
      r & 567426 & 2016-08-25 & 400 & 1.53 & 23.99 \\
      r & 569613 & 2016-08-31 & 400 & 1.18 & 24.82 \\
      r & 571060 & 2016-09-05 & 400 & 1.64 & 24.51 \\
      r & 573562 & 2016-09-11 & 400 & 1.34 & 24.19 \\
      r & 574711 & 2016-09-14 & 400 & 1.47 & 23.82 \\
      r & 575798 & 2016-09-22 & 400 & 1.07 & 24.33 \\
      r & 576542 & 2016-09-24 & 400 & 1.67 & 24.44 \\
      r & 578740 & 2016-09-29 & 400 & 1.54 & 24.46 \\
      r & 580295 & 2016-10-03 & 400 & 1.62 & 24.34 \\
      r & 582423 & 2016-10-10 & 400 & 1.07 & 24.12 \\
      r & 584144 & 2016-10-20 & 400 & 1.55 & 23.91 \\
      r & 585892 & 2016-10-25 & 400 & 1.90 & 24.15 \\
      r & 588624 & 2016-11-02 & 400 & 1.25 & 24.61 \\
      r & 591453 & 2016-11-09 & 400 & 1.16 & 24.30 \\
      r & 593076 & 2016-11-16 & 400 & 1.15 & 23.52 \\
      r & 593387 & 2016-11-17 & 400 & 1.35 & 24.64 \\
      r & 595359 & 2016-11-23 & 400 & 1.85 & 24.20 \\
      r & 597239 & 2016-11-28 & 400 & 1.84 & 24.33 \\
      r & 598940 & 2016-12-03 & 400 & 1.43 & 24.46 \\
      r & 600880 & 2016-12-08 & 400 & 2.67 & 23.26 \\
      r & 601776 & 2016-12-18 & 400 & 1.20 & 24.98 \\
      r & 604334 & 2016-12-25 & 400 & 1.01 & 25.05 \\
      r & 605255 & 2016-12-30 & 400 & 1.50 & 24.64 \\
      \hline \\
      i & 563972 & 2016-08-14 & 360 & 1.77 & 23.49 \\
      i & 566980 & 2016-08-24 & 360 & 1.35 & 23.61 \\
      i & 567442 & 2016-08-25 & 360 & 1.05 & 24.20 \\
      i & 567867 & 2016-08-26 & 360 & 1.04 & 24.24 \\
      i & 570175 & 2016-09-02 & 360 & 1.81 & 23.10 \\
      i & 571447 & 2016-09-06 & 360 & 1.54 & 23.23 \\
      i & 573865 & 2016-09-12 & 360 & 1.66 & 23.01 \\
      i & 574727 & 2016-09-14 & 360 & 1.80 & 22.73 \\
      i & 575802 & 2016-09-22 & 360 & 1.09 & 23.13 \\
      i & 576546 & 2016-09-24 & 360 & 1.41 & 23.33 \\
      i & 579449 & 2016-10-01 & 360 & 1.15 & 23.41 \\
      i & 581861 & 2016-10-08 & 360 & 1.47 & 23.03 \\
      i & 584166 & 2016-10-20 & 360 & 1.27 & 23.01 \\
      i & 585960 & 2016-10-25 & 360 & 1.73 & 22.89 \\
      i & 588628 & 2016-11-02 & 360 & 1.20 & 23.93 \\
      i & 591457 & 2016-11-09 & 360 & 1.06 & 24.00 \\
      i & 593080 & 2016-11-16 & 360 & 1.03 & 23.51 \\
      i & 595056 & 2016-11-22 & 360 & 1.81 & 23.75 \\
      i & 596517 & 2016-11-26 & 360 & 1.61 & 24.00 \\
      i & 598236 & 2016-12-01 & 360 & 1.38 & 23.88 \\
      i & 600850 & 2016-12-08 & 360 & 1.04 & 24.12 \\
      i & 601780 & 2016-12-18 & 360 & 1.12 & 24.44 \\
      i & 604338 & 2016-12-25 & 360 & 1.14 & 24.23 \\
      i & 605266 & 2016-12-30 & 360 & 1.67 & 23.90 \\
      i & 607844 & 2017-01-09 & 360 & 1.34 & 22.65 \\
    \end{tabular}
    \caption{Exposures from the Dark Energy Camera used in the
      experiments.\label{tab:exposures}}
  \end{center}
\end{table}




\end{document}

